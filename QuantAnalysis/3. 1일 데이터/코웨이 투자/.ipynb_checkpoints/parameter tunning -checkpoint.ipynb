{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from xgboost import  XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "if platform.system() == 'Darwin':    # 맥\n",
    "    rc( 'font', family='AppleGothic' )\n",
    "elif platform.system() == 'Windows': # 윈도우\n",
    "    fontPath = 'c:/Windows/Fonts/malgun.ttf'\n",
    "    fontName = font_manager.FontProperties( fname=fontPath ).get_name()\n",
    "    rc( 'font', family=fontName )\n",
    "else:\n",
    "    print('알수없는 시스템. 미적용')\n",
    "    \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_excel('./true.xlsx')\n",
    "\n",
    "col = ['종가 (5일 평균)(원)_1일변화율',\n",
    "       '변동성 (5일)_1일변화율', '순매수수량(외국인계)(20일합산)(주)_1일변화율', 'PER(IFRS-연결)_1일변화율',\n",
    "       '순매수수량(개인)(20일합산)(주)_1일변화율', '종가 (60일 평균)(원)_1일변화율',\n",
    "       '거래량 (20일 평균)(주)_1일변화율', '순매수수량(외국인계)(60일합산)(주)_1일변화율',\n",
    "       '순매수수량(기관/외국인계)(60일합산)(주)_1일변화율', '순매수수량(외국인계)(주)_1일변화율',\n",
    "       '순매수수량(기관계)(주)_1일변화율', '순매수수량(기관계)(60일합산)(주)_1일변화율',\n",
    "       '순매수수량(개인)(주)_1일변화율', '외국인보유비중(티커)(%)_1일변화율', 'PSR(IFRS-연결)_1일변화율',\n",
    "       '종가 (120일 평균)(원)_1일변화율', '종가 (20일 평균)(원)_1일변화율',\n",
    "       '순매수수량(개인)(60일합산)(주)_1일변화율', '거래량 (60일 평균)(주)_1일변화율',\n",
    "       'PCR(IFRS-연결)_1일변화율', '순매수수량(기관/외국인계)(20일합산)(주)_1일변화율',\n",
    "       '순매수수량(기관계)(20일합산)(주)_1일변화율', '수익률 (1주)(%)_1일변화율', 'PBR(IFRS-연결)_1일변화율',\n",
    "       '거래량 (5일 평균)(주)_1일변화율', '순매수수량(기관/외국인계)(주)_1일변화율',\n",
    "       '종가 (5일 평균)(원)_2일변화율', '변동성 (5일)_2일변화율', '순매수수량(외국인계)(20일합산)(주)_2일변화율',\n",
    "       'PER(IFRS-연결)_2일변화율', '순매수수량(개인)(20일합산)(주)_2일변화율',\n",
    "       '종가 (60일 평균)(원)_2일변화율', '거래량 (20일 평균)(주)_2일변화율',\n",
    "       '순매수수량(외국인계)(60일합산)(주)_2일변화율', '순매수수량(기관/외국인계)(60일합산)(주)_2일변화율',\n",
    "       '순매수수량(외국인계)(주)_2일변화율', '순매수수량(기관계)(주)_2일변화율',\n",
    "       '순매수수량(기관계)(60일합산)(주)_2일변화율', '순매수수량(개인)(주)_2일변화율',\n",
    "       '외국인보유비중(티커)(%)_2일변화율', 'PSR(IFRS-연결)_2일변화율', '종가 (120일 평균)(원)_2일변화율',\n",
    "       '종가 (20일 평균)(원)_2일변화율', '순매수수량(개인)(60일합산)(주)_2일변화율',\n",
    "       '거래량 (60일 평균)(주)_2일변화율', 'PCR(IFRS-연결)_2일변화율',\n",
    "       '순매수수량(기관/외국인계)(20일합산)(주)_2일변화율', '순매수수량(기관계)(20일합산)(주)_2일변화율',\n",
    "       '수익률 (1주)(%)_2일변화율', 'PBR(IFRS-연결)_2일변화율', '거래량 (5일 평균)(주)_2일변화율',\n",
    "       '순매수수량(기관/외국인계)(주)_2일변화율','수익률(%)(2)','Name']\n",
    "data =  final_dataset[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sp(data):\n",
    "    com_name_set = list(set(data.Name))\n",
    "    \n",
    "    train_set = pd.DataFrame()\n",
    "    test_set = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(com_name_set)):\n",
    "        sub_set = data[ data.Name == com_name_set[i]]\n",
    "        train_set = train_set.append(sub_set[:-60])\n",
    "        test_set = test_set.append(sub_set[-60:])\n",
    "    return train_set , test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test = data_sp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1305, 54) (60, 54)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 튜닝\n",
    "파라미터 튜닝을 해주는 모듈이 있는데 그 모듈을 사용할 경우 일반적인 교차검증을 한 상태로 결과를 비교하기에 쓸수가 없었다.\n",
    "그래서 직접 파라미터 값들을 넣고 줄여나가는 식으로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['순매수수량(외국인계)(60일합산)(주)_1일변화율',\n",
    " '순매수수량(기관/외국인계)(60일합산)(주)_1일변화율',\n",
    " '순매수수량(외국인계)(주)_1일변화율',\n",
    " '순매수수량(기관계)(주)_1일변화율',\n",
    " '종가 (120일 평균)(원)_1일변화율',\n",
    " '종가 (20일 평균)(원)_1일변화율',\n",
    " '순매수수량(기관계)(20일합산)(주)_1일변화율',\n",
    " '거래량 (5일 평균)(주)_1일변화율',\n",
    " '순매수수량(기관/외국인계)(주)_1일변화율',\n",
    " 'PER(IFRS-연결)_2일변화율',\n",
    " '종가 (60일 평균)(원)_2일변화율',\n",
    " '순매수수량(외국인계)(60일합산)(주)_2일변화율',\n",
    " '거래량 (60일 평균)(주)_2일변화율',\n",
    " '수익률 (1주)(%)_2일변화율',\n",
    " '거래량 (5일 평균)(주)_2일변화율']\n",
    "X_train = train[col]\n",
    "X_test = test[col]\n",
    "\n",
    "Y_train = train['수익률(%)(2)']\n",
    "Y_test = test['수익률(%)(2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtestdata = pd.read_excel('./act.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "val_acc = []\n",
    "acc = []\n",
    "pre= []\n",
    "param = []\n",
    "for i in [4,5,6]:\n",
    "    print(i)\n",
    "    for b in [0.01,0.05, 0.1]:\n",
    "        for c in [0,1,2,]:\n",
    "            for d in [0.5,1,2,3]:\n",
    "                for f in [0.8,0.9,1]:\n",
    "                    for g in [100]:\n",
    "                        model = XGBClassifier(max_depth=i, \n",
    "                                              learning_rate=b,\n",
    "                                              n_estimators = g,\n",
    "                                              gamma = c,\n",
    "                                              min_child_weight=d,\n",
    "                                              colsample_bytree= f,\n",
    "                                              n_jobs=-1)\n",
    "\n",
    "                        model.fit(X_train ,Y_train)\n",
    "                        j = model.predict(X_train)\n",
    "                        a = model.predict(X_test)\n",
    "                        t = metrics.confusion_matrix(Y_test,a)\n",
    "                        \n",
    "                        val_acc.append(metrics.accuracy_score(j, Y_train))\n",
    "                        acc.append(metrics.accuracy_score(a,Y_test))\n",
    "                        pre.append(t[1,1]/t[:,1].sum())\n",
    "                        param.append(model)\n",
    "\n",
    "result = pd.concat([pd.DataFrame(val_acc),pd.DataFrame(acc),abs(pd.DataFrame(val_acc) - pd.DataFrame(acc)),pd.DataFrame(pre),pd.DataFrame(param)],axis=1)\n",
    "result.columns = ['val_acc','acc','mi','pre','paremeter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel('./tuning_result1.xlsx',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#result2\n",
    "\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.9, gamma=1, learning_rate=0.05, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1)\n",
    "       \n",
    "val / test 차이가 적고 성능이 좋아서 이 파라미터를 기준으로 파라미터 서칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "pre= []\n",
    "param = []\n",
    "for i in [5]:\n",
    "    print(i)\n",
    "    for b in np.linspace(0.03,0.07,5):\n",
    "        for c in np.linspace(0.8, 1.2, 5):\n",
    "            for d in np.linspace(0.8, 1.2, 5):\n",
    "                for f in [0.85, 0.9, 0.95]:\n",
    "                    for g in [100]:\n",
    "                        model = XGBClassifier(max_depth=i, \n",
    "                                              learning_rate=b,\n",
    "                                              n_estimators = g,\n",
    "                                              gamma = c,\n",
    "                                              min_child_weight=d,\n",
    "                                              colsample_bytree= f,\n",
    "                                              n_jobs=-1)\n",
    "\n",
    "                        model.fit(X_train ,Y_train)\n",
    "                        a = model.predict(X_test)\n",
    "                        t = metrics.confusion_matrix(Y_test,a)\n",
    "\n",
    "                        val_acc.append(metrics.accuracy_score(j, Y_train))\n",
    "                        acc.append(metrics.accuracy_score(a,Y_test))\n",
    "                        pre.append(t[1,1]/t[:,1].sum())\n",
    "                        param.append(model)\n",
    "\n",
    "result2 = pd.concat([pd.DataFrame(val_acc),pd.DataFrame(acc),abs(pd.DataFrame(val_acc) - pd.DataFrame(acc)),pd.DataFrame(pre),pd.DataFrame(param)],axis=1)\n",
    "result2.columns = ['val_acc','acc','mi','pre','paremeter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_excel('./tuning_result2.xlsx',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 \n",
    "acc가 가장 높은 모델을 봤을 때 val_acc와 acc의 차이가 6%로 차이가 심했다.   \n",
    "그래서 val_acc와 acc의 차이가 1% 미만이고 성능 또한 우수한 모델을 찾았다.\n",
    "acc가 같은 경우 precision순으로 뽑았다.\n",
    "\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.9, gamma=1.2, learning_rate=0.07,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=1.0, missing=None,\n",
    "       n_estimators=100, n_jobs=-1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "       \n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.9, gamma=1.2, learning_rate=0.07,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=1.1, missing=None,\n",
    "       n_estimators=100, n_jobs=-1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "       \n",
    "2개의 모델이 나왔다.  min_child_weight가 0.1 차이 났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>pre</th>\n",
       "      <th>paremeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acc       pre  paremeter\n",
       "0   0.7  0.689655        100\n",
       "1   0.7  0.689655        300\n",
       "2   0.7  0.689655        500\n",
       "3   0.7  0.689655        800\n",
       "4   0.7  0.689655       1000\n",
       "5   0.7  0.689655       1500\n",
       "6   0.7  0.689655       2000\n",
       "7   0.7  0.689655       2500\n",
       "8   0.7  0.689655       3000\n",
       "9   0.7  0.689655       4000\n",
       "10  0.7  0.689655       5000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc4 = []\n",
    "pre4= []\n",
    "param4 = []\n",
    "# 7은 상위권에 없었다. \n",
    "for d in [100,300,500,800,1000,1500,2000,2500,3000,4000,5000]:\n",
    "    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "   colsample_bytree=0.95, gamma=0.9, learning_rate=0.07,\n",
    "   max_delta_step=0, max_depth=5, min_child_weight=1.1, missing=None,\n",
    "   n_estimators=d, n_jobs=-1, nthread=None,\n",
    "   objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "   reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "   subsample=1)\n",
    "\n",
    "    model.fit(X_train ,Y_train)\n",
    "    a = model.predict(X_test)\n",
    "    t = metrics.confusion_matrix(Y_test,a)\n",
    "\n",
    "    acc4.append(metrics.accuracy_score(a,Y_test))\n",
    "    pre4.append(t[1,1]/t[:,1].sum())\n",
    "    param4.append(d)\n",
    "\n",
    "result4 = pd.concat([pd.DataFrame(acc4),pd.DataFrame(pre4),pd.DataFrame(param4)],axis=1)\n",
    "result4.columns = ['acc','pre','paremeter']\n",
    "result4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators에 의한 성능차이는 없었다 이는 적은 수의 트리로만으로도 분석에 충분하다는 의미다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back testing\n",
    "- 필자는 HP노트북인데 같은 random_state를 주어도 나 이외의 컴퓨터와는 다른 결과를 얻는 신기한(?) 경험을 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtestdata = pd.read_excel('./act.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 0.71667, acc: 0.625, pre:0.75 \n",
      " [[11  3]\n",
      " [ 9  9]]\n"
     ]
    }
   ],
   "source": [
    "## keep\n",
    "X_train = train[col]\n",
    "X_test = test[col]\n",
    "X_backtestdata = backtestdata[col]\n",
    "\n",
    "Y_train = train['수익률(%)(2)']\n",
    "Y_test = test['수익률(%)(2)']\n",
    "Y_backtestdata = backtestdata['수익률(%)(2)']\n",
    "\n",
    "model =XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.9, gamma=1.2, learning_rate=0.07,\n",
    "       max_delta_step=0, max_depth=5, min_child_weight=1.0, missing=None,\n",
    "       n_estimators=100, n_jobs=-1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "\n",
    "model.fit(X_train[col] ,Y_train)\n",
    "a = model.predict(X_test[col])\n",
    "b = model.predict(X_backtestdata[col])\n",
    "t = metrics.confusion_matrix(Y_backtestdata,b)\n",
    "print('val: {x:.5}, acc: {y:.5}, pre:{g:.5}'.format(x = metrics.accuracy_score(a,Y_test), y = metrics.accuracy_score(b,Y_backtestdata),\n",
    "                                                     g = t[1,1]/t[:,1].sum() ),'\\n', metrics.confusion_matrix(Y_backtestdata,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "if not sys.modules.get('pyarrow'):\n",
    "    os.system('pip3 install pyarrow')\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import datetime \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_vouch(m):\n",
    "    if len(str(m))==1:\n",
    "        return '0'+str(m)\n",
    "    else:\n",
    "        return str(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_cor(a,b):   \n",
    "    if a.shape != b.shape:\n",
    "        print('크기가 다른 데이터입니다.')            \n",
    "    else:\n",
    "        return((np.dot(a,b) - np.mean(a)*np.mean(b)*a.shape[0])/(a.shape[0]-1))/(np.std(a)*np.std(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "# 한글처리\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "if platform.system() == 'Darwin':    # 맥\n",
    "    rc( 'font', family='AppleGothic' )\n",
    "elif platform.system() == 'Windows': # 윈도우\n",
    "    # 폰트 차후 확인\n",
    "    fontPath = 'c:/Windows/Fonts/malgun.ttf'\n",
    "    fontName = font_manager.FontProperties( fname=fontPath ).get_name()\n",
    "    rc( 'font', family=fontName )\n",
    "else:\n",
    "    print('알수없는 시스템. 미적용')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "if not sys.modules.get('xgboost'):\n",
    "    os.system('pip3 install xgboost')\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_code = '021240'\n",
    "path = './data/freq2/naver_{0}_freq.parquet/'.format(stock_code)\n",
    "file_name = os.listdir(path)[0]\n",
    "data = pd.read_parquet(path+file_name)\n",
    "#data['date'] = pd.to_datetime(data['date'], format='%Y.%m.%d', errors='ignore')\n",
    "tag_dict= Counter()\n",
    "all_dict = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorting = data.sort_values(by='date')\n",
    "data_sorting.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for columns in data_sorting.columns:\n",
    "#     if columns.find('기도')>=0:\n",
    "#         print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고려해야할 것\n",
    "- 각 컬럼의 총 빈도를 계산하여 특정 빈도 이하는 제거\n",
    "- 날짜 짝짓기\n",
    "- 전날과 당일 빈도 묶기 - 주말,휴일 고려 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#특정 이하 빈도 제거 \n",
    "sum_by_columns = data_sorting.drop(columns=['date']).sum(axis=0)\n",
    "abs_path = os.path.abspath('../file_list/crawl_data/naver_{0}.csv'.format(stock_code))\n",
    "csv_file = pd.read_csv(abs_path,header=None)\n",
    "#print(csv_file.head(10))\n",
    "filter_size = csv_file.shape[0]*0.02\n",
    "filtered_index_series = sum_by_columns>filter_size\n",
    "filtered_index = filtered_index_series[filtered_index_series==True].keys()\n",
    "#date_list = ['date']\n",
    "#data['date'].concat(sum_by_columns>filter_size)\n",
    "\n",
    "#data_filter_freq = data_sorting.loc[:date_list.extend(filtered_index)]\n",
    "data_filter_freq = data_sorting.loc[:,filtered_index]\n",
    "# 수익률과 날짜를 맞춰주기 위해서 하루를 미뤄준다.\n",
    "\n",
    "#day를 더해줬던 이유가 무엇일까?\n",
    "data_filter_freq.index = data_sorting['date'].apply(lambda x:datetime.datetime(int(x.split('.')[0]),int(x.split('.')[1]),int(x.split('.')[2]))+relativedelta(days=1))\n",
    "data_filter_freq = data_filter_freq.loc[:datetime.datetime(2018,11,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for columns in data_filter_freq.columns:\n",
    "#     if columns.find('김가')>=0:\n",
    "#         print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!!/sf</th>\n",
       "      <th>!/sf</th>\n",
       "      <th>........................./se</th>\n",
       "      <th>......................../se</th>\n",
       "      <th>......................./se</th>\n",
       "      <th>....................../se</th>\n",
       "      <th>...................../se</th>\n",
       "      <th>..................../se</th>\n",
       "      <th>.................../se</th>\n",
       "      <th>................../se</th>\n",
       "      <th>...</th>\n",
       "      <th>홀딩/nng</th>\n",
       "      <th>홀딩스/nng</th>\n",
       "      <th>확보/nng</th>\n",
       "      <th>확인/nng</th>\n",
       "      <th>환율/nng</th>\n",
       "      <th>회사/nng</th>\n",
       "      <th>회장/nng</th>\n",
       "      <th>후/nng</th>\n",
       "      <th>휴맥/nng</th>\n",
       "      <th>힘/nng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            !!/sf  !/sf  ........................./se  \\\n",
       "date                                                    \n",
       "2018-11-25      0     0                             0   \n",
       "2018-11-27      0     0                             0   \n",
       "2018-11-28      0     0                             0   \n",
       "2018-11-29      0     0                             0   \n",
       "2018-11-30      0     0                             0   \n",
       "\n",
       "            ......................../se  ......................./se  \\\n",
       "date                                                                  \n",
       "2018-11-25                            0                           0   \n",
       "2018-11-27                            0                           0   \n",
       "2018-11-28                            0                           0   \n",
       "2018-11-29                            0                           0   \n",
       "2018-11-30                            0                           0   \n",
       "\n",
       "            ....................../se  ...................../se  \\\n",
       "date                                                              \n",
       "2018-11-25                          0                         0   \n",
       "2018-11-27                          0                         0   \n",
       "2018-11-28                          0                         0   \n",
       "2018-11-29                          0                         0   \n",
       "2018-11-30                          0                         0   \n",
       "\n",
       "            ..................../se  .................../se  \\\n",
       "date                                                          \n",
       "2018-11-25                        0                       0   \n",
       "2018-11-27                        0                       0   \n",
       "2018-11-28                        0                       0   \n",
       "2018-11-29                        0                       0   \n",
       "2018-11-30                        0                       0   \n",
       "\n",
       "            ................../se  ...    홀딩/nng  홀딩스/nng  확보/nng  확인/nng  \\\n",
       "date                               ...                                      \n",
       "2018-11-25                      0  ...         0        0       0       0   \n",
       "2018-11-27                      0  ...         0        0       0       0   \n",
       "2018-11-28                      0  ...         0        0       0       0   \n",
       "2018-11-29                      0  ...         0        0       0       0   \n",
       "2018-11-30                      0  ...         0        0       0       0   \n",
       "\n",
       "            환율/nng  회사/nng  회장/nng  후/nng  휴맥/nng  힘/nng  \n",
       "date                                                      \n",
       "2018-11-25       0       0       0      0       0      0  \n",
       "2018-11-27       0       1       0      0       0      0  \n",
       "2018-11-28       0       0       0      0       0      0  \n",
       "2018-11-29       0       0       0      0       0      0  \n",
       "2018-11-30       0       0       0      0       0      0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filter_freq.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_freq_ori = data_filter_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 보류\n",
    "#날짜 짝짓기\n",
    "#첫행 처리는 어떻게 할것인가? 없으면 더해주지 않는다. 있으면 더한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7월 30일 데이터는 없다.\n",
    "#data_filter_freq.loc[datetime.datetime(year=2017,month=7,day=30),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수익률 데이터 처리\n",
    "earning_month_raw = pd.read_excel('./data/코웨이수익률.xlsx')\n",
    "earning_month_raw.index = earning_month_raw['date']\n",
    "del earning_month_raw['date']\n",
    "earning_data = earning_month_raw.loc[datetime.datetime(year=2017,month=6,day=8):datetime.datetime(year=2018,month=11,day=30),'return']\n",
    "# 해당 열 추출\n",
    "# symbol = earning_month_raw.loc[:,'A'+stock_code]\n",
    "# return_data =symbol\n",
    "# earning_data = return_data[datetime.datetime(year=2017,month=6,day=8):datetime.datetime(year=2018,month=11,day=30)]\n",
    "#earning_data = earning_month_raw[datetime.datetime(year=2017,month=6,day=8):datetime.datetime(year=2018,month=11,day=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수익률 데이터 처리\n",
    "# stock_code = '015760'\n",
    "# earning_month_raw = pd.read_excel('./data/현대차,한전_수익률.xlsx')\n",
    "# # 해당 열 추출\n",
    "# symbol = earning_month_raw.loc[:,'A'+stock_code]\n",
    "# return_data =symbol\n",
    "\n",
    "# earning_data = return_data[datetime.datetime(year=2017,month=6,day=8):datetime.datetime(year=2018,month=11,day=30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 수익률 데이터 처리\n",
    "# earning_month_raw = pd.read_excel('./data/일일수익률.xlsx')\n",
    "\n",
    "# symbol = earning_month_raw.loc['Symbol Name':,:]\n",
    "# symbol.columns = earning_month_raw.loc['Symbol']\n",
    "\n",
    "# # 해당 열 추출\n",
    "# return_data = symbol['A'+stock_code]\n",
    "\n",
    "\n",
    "# earning_data = return_data[datetime.datetime(year=2017,month=6,day=8):datetime.datetime(year=2018,month=11,day=30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-06-08    1\n",
       "2017-06-09    1\n",
       "2017-06-12    1\n",
       "2017-06-13    0\n",
       "2017-06-14    0\n",
       "Name: return, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(earning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "earning_data_ori = earning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(earning_data_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5001994813564293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(list(earning_data))\n",
    "print(earning_data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x253a2f488d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(earning_data.index,earning_data) #일일 변화율은 안정적인 편이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x253a2cfcf98>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(earning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earning_data의 전날 텍스트 빈도와 earning_data의 수익률의 짝을 맞춰야한다. \n",
    "# 주말과 휴일을 고려해야한다.\n",
    "# 합치기 위해서는 earning_data의 index 정보가 필요하다.\n",
    "\n",
    "#earning_data.index =  [date- relativedelta(days=1) for date in earning_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2018-11-26    0\n",
       "2018-11-27    1\n",
       "2018-11-28    0\n",
       "2018-11-29    1\n",
       "2018-11-30    0\n",
       "Name: return, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earning_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-06-08', '2017-06-09', '2017-06-11', '2017-06-13',\n",
       "               '2017-06-16', '2017-06-18', '2017-06-23', '2017-06-29',\n",
       "               '2017-06-30', '2017-07-04',\n",
       "               ...\n",
       "               '2018-11-17', '2018-11-20', '2018-11-22', '2018-11-23',\n",
       "               '2018-11-24', '2018-11-25', '2018-11-27', '2018-11-28',\n",
       "               '2018-11-29', '2018-11-30'],\n",
       "              dtype='datetime64[ns]', name='date', length=288, freq=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 날짜에 있는 빈도를 수익률과 상관계수를 구할거임\n",
    "data_filter_freq.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(differ_date[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = differ_date[0:2]\n",
    "# a.append('babo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differ_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 501)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filter_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### 안되는 이유: 컬럼 갯수가 계속해서 줄어 들기 때문에 idx가 줄어든 갯수를 넘어가면 out of index bound 에러가 난다.\n",
    "# for idx in range(data_filter_freq.shape[1]):\n",
    "#     print(idx)\n",
    "#     tag = data_filter_freq.iloc[:,idx]    \n",
    "#     tag_name = tag.name\n",
    "#     print(tag_name)\n",
    "#     #print(data_filter_freq.columns)\n",
    "#     if tag_name == './sf'or tag_name.find('/sw')>=0 or tag_name.find('/sn')>=0:\n",
    "#         #del data_filter_freq.iloc[:,idx]\n",
    "#         data_filter_freq.drop(columns=tag_name,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#필요 없다고 생각되는 태그 제거\n",
    "\n",
    "delete_column_list = []\n",
    "for idx in range(data_filter_freq.shape[1]):\n",
    "    \n",
    "    tag = data_filter_freq.iloc[:,idx]    \n",
    "    tag_name = tag.name    \n",
    "    \n",
    "    if tag_name == './sf'or tag_name.find('/sw')>=0 or tag_name.find('/sn')>=0:\n",
    "        delete_column_list.append(tag_name)\n",
    "        \n",
    "data_filter_freq.drop(columns=delete_column_list,inplace=True,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "differ_date = sorted(list(set(data_filter_freq.index).difference(set(earning_data.index))))\n",
    "#print(differ_date)\n",
    "i = 0\n",
    "for idx in range(len(differ_date)-1):\n",
    "    #print(element)\n",
    "    # 10 11 17 idx = 1\n",
    "    if (differ_date[idx+1]-differ_date[idx]).days > 1:      \n",
    "        #print(differ_date[i],differ_date[idx+1],data_filter_freq.loc[differ_date[i:idx+1],:].sum())\n",
    "        # 휴일 or 주말이 끼면 그 날을 포함해서 다음 날에 반영한다.\n",
    "        # 휴일 다음날 \n",
    "        append_idx = differ_date[idx]+relativedelta(days=1)\n",
    "        sum_list = differ_date[i:idx+1]\n",
    "        sum_list.append(append_idx)\n",
    "        data_filter_freq.loc[append_idx,:] = data_filter_freq.loc[sum_list,:].sum()//len(sum_list)\n",
    "        data_filter_freq.drop(index = differ_date[i:idx+1],inplace=True)\n",
    "        #del data_filter_freq.loc[differ_date[i:idx+1],:]\n",
    "        #print(sum_list,'append_idx:',append_idx)\n",
    "        i = idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247 358\n"
     ]
    }
   ],
   "source": [
    "print(len(data_filter_freq),len(earning_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ_date1 = sorted(list(set(data_filter_freq.index).difference(set(earning_data.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2017-07-23 00:00:00'),\n",
       " Timestamp('2017-08-06 00:00:00'),\n",
       " Timestamp('2017-08-13 00:00:00'),\n",
       " Timestamp('2017-08-20 00:00:00'),\n",
       " Timestamp('2017-08-27 00:00:00'),\n",
       " Timestamp('2017-09-10 00:00:00'),\n",
       " Timestamp('2017-09-17 00:00:00'),\n",
       " Timestamp('2017-09-24 00:00:00'),\n",
       " Timestamp('2017-10-03 00:00:00'),\n",
       " Timestamp('2017-10-15 00:00:00'),\n",
       " Timestamp('2017-10-29 00:00:00'),\n",
       " Timestamp('2017-11-05 00:00:00'),\n",
       " Timestamp('2017-11-19 00:00:00'),\n",
       " Timestamp('2017-12-24 00:00:00'),\n",
       " Timestamp('2017-12-30 00:00:00'),\n",
       " Timestamp('2018-01-14 00:00:00'),\n",
       " Timestamp('2018-01-21 00:00:00'),\n",
       " Timestamp('2018-02-18 00:00:00'),\n",
       " Timestamp('2018-03-04 00:00:00'),\n",
       " Timestamp('2018-03-25 00:00:00'),\n",
       " Timestamp('2018-04-01 00:00:00'),\n",
       " Timestamp('2018-04-22 00:00:00'),\n",
       " Timestamp('2018-05-07 00:00:00'),\n",
       " Timestamp('2018-06-24 00:00:00'),\n",
       " Timestamp('2018-07-08 00:00:00'),\n",
       " Timestamp('2018-08-19 00:00:00'),\n",
       " Timestamp('2018-08-26 00:00:00'),\n",
       " Timestamp('2018-09-25 00:00:00'),\n",
       " Timestamp('2018-10-14 00:00:00'),\n",
       " Timestamp('2018-10-28 00:00:00'),\n",
       " Timestamp('2018-11-18 00:00:00'),\n",
       " Timestamp('2018-11-24 00:00:00'),\n",
       " Timestamp('2018-11-25 00:00:00')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differ_date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_freq.drop(differ_date1,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ_date2 = sorted(list(set(earning_data.index).difference(set(data_filter_freq.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2017-06-14 00:00:00'),\n",
       " Timestamp('2017-06-15 00:00:00'),\n",
       " Timestamp('2017-06-20 00:00:00'),\n",
       " Timestamp('2017-06-21 00:00:00'),\n",
       " Timestamp('2017-06-22 00:00:00'),\n",
       " Timestamp('2017-06-26 00:00:00'),\n",
       " Timestamp('2017-06-27 00:00:00'),\n",
       " Timestamp('2017-07-05 00:00:00'),\n",
       " Timestamp('2017-07-06 00:00:00'),\n",
       " Timestamp('2017-07-07 00:00:00'),\n",
       " Timestamp('2017-07-10 00:00:00'),\n",
       " Timestamp('2017-07-11 00:00:00'),\n",
       " Timestamp('2017-07-14 00:00:00'),\n",
       " Timestamp('2017-07-25 00:00:00'),\n",
       " Timestamp('2017-07-26 00:00:00'),\n",
       " Timestamp('2017-07-28 00:00:00'),\n",
       " Timestamp('2017-07-31 00:00:00'),\n",
       " Timestamp('2017-08-01 00:00:00'),\n",
       " Timestamp('2017-08-07 00:00:00'),\n",
       " Timestamp('2017-08-10 00:00:00'),\n",
       " Timestamp('2017-08-14 00:00:00'),\n",
       " Timestamp('2017-08-16 00:00:00'),\n",
       " Timestamp('2017-08-17 00:00:00'),\n",
       " Timestamp('2017-08-18 00:00:00'),\n",
       " Timestamp('2017-08-21 00:00:00'),\n",
       " Timestamp('2017-08-23 00:00:00'),\n",
       " Timestamp('2017-08-24 00:00:00'),\n",
       " Timestamp('2017-08-25 00:00:00'),\n",
       " Timestamp('2017-08-28 00:00:00'),\n",
       " Timestamp('2017-08-29 00:00:00'),\n",
       " Timestamp('2017-08-31 00:00:00'),\n",
       " Timestamp('2017-09-05 00:00:00'),\n",
       " Timestamp('2017-09-08 00:00:00'),\n",
       " Timestamp('2017-09-11 00:00:00'),\n",
       " Timestamp('2017-09-12 00:00:00'),\n",
       " Timestamp('2017-09-13 00:00:00'),\n",
       " Timestamp('2017-09-14 00:00:00'),\n",
       " Timestamp('2017-09-18 00:00:00'),\n",
       " Timestamp('2017-09-20 00:00:00'),\n",
       " Timestamp('2017-09-21 00:00:00'),\n",
       " Timestamp('2017-09-22 00:00:00'),\n",
       " Timestamp('2017-09-25 00:00:00'),\n",
       " Timestamp('2017-09-26 00:00:00'),\n",
       " Timestamp('2017-09-29 00:00:00'),\n",
       " Timestamp('2017-10-10 00:00:00'),\n",
       " Timestamp('2017-10-11 00:00:00'),\n",
       " Timestamp('2017-10-12 00:00:00'),\n",
       " Timestamp('2017-10-16 00:00:00'),\n",
       " Timestamp('2017-10-19 00:00:00'),\n",
       " Timestamp('2017-10-20 00:00:00'),\n",
       " Timestamp('2017-10-23 00:00:00'),\n",
       " Timestamp('2017-10-24 00:00:00'),\n",
       " Timestamp('2017-10-25 00:00:00'),\n",
       " Timestamp('2017-10-26 00:00:00'),\n",
       " Timestamp('2017-10-30 00:00:00'),\n",
       " Timestamp('2017-10-31 00:00:00'),\n",
       " Timestamp('2017-11-01 00:00:00'),\n",
       " Timestamp('2017-11-06 00:00:00'),\n",
       " Timestamp('2017-11-07 00:00:00'),\n",
       " Timestamp('2017-11-09 00:00:00'),\n",
       " Timestamp('2017-11-13 00:00:00'),\n",
       " Timestamp('2017-11-14 00:00:00'),\n",
       " Timestamp('2017-11-15 00:00:00'),\n",
       " Timestamp('2017-11-16 00:00:00'),\n",
       " Timestamp('2017-11-17 00:00:00'),\n",
       " Timestamp('2017-11-20 00:00:00'),\n",
       " Timestamp('2017-11-21 00:00:00'),\n",
       " Timestamp('2017-11-23 00:00:00'),\n",
       " Timestamp('2017-11-24 00:00:00'),\n",
       " Timestamp('2017-11-28 00:00:00'),\n",
       " Timestamp('2017-11-29 00:00:00'),\n",
       " Timestamp('2017-11-30 00:00:00'),\n",
       " Timestamp('2017-12-06 00:00:00'),\n",
       " Timestamp('2017-12-07 00:00:00'),\n",
       " Timestamp('2017-12-11 00:00:00'),\n",
       " Timestamp('2017-12-13 00:00:00'),\n",
       " Timestamp('2017-12-14 00:00:00'),\n",
       " Timestamp('2017-12-15 00:00:00'),\n",
       " Timestamp('2017-12-19 00:00:00'),\n",
       " Timestamp('2018-01-02 00:00:00'),\n",
       " Timestamp('2018-01-03 00:00:00'),\n",
       " Timestamp('2018-01-10 00:00:00'),\n",
       " Timestamp('2018-01-11 00:00:00'),\n",
       " Timestamp('2018-01-12 00:00:00'),\n",
       " Timestamp('2018-01-22 00:00:00'),\n",
       " Timestamp('2018-01-24 00:00:00'),\n",
       " Timestamp('2018-01-25 00:00:00'),\n",
       " Timestamp('2018-01-26 00:00:00'),\n",
       " Timestamp('2018-02-05 00:00:00'),\n",
       " Timestamp('2018-02-20 00:00:00'),\n",
       " Timestamp('2018-02-21 00:00:00'),\n",
       " Timestamp('2018-02-27 00:00:00'),\n",
       " Timestamp('2018-03-06 00:00:00'),\n",
       " Timestamp('2018-03-08 00:00:00'),\n",
       " Timestamp('2018-03-09 00:00:00'),\n",
       " Timestamp('2018-03-26 00:00:00'),\n",
       " Timestamp('2018-03-28 00:00:00'),\n",
       " Timestamp('2018-03-29 00:00:00'),\n",
       " Timestamp('2018-04-02 00:00:00'),\n",
       " Timestamp('2018-04-03 00:00:00'),\n",
       " Timestamp('2018-04-23 00:00:00'),\n",
       " Timestamp('2018-05-02 00:00:00'),\n",
       " Timestamp('2018-06-01 00:00:00'),\n",
       " Timestamp('2018-06-14 00:00:00'),\n",
       " Timestamp('2018-06-18 00:00:00'),\n",
       " Timestamp('2018-06-19 00:00:00'),\n",
       " Timestamp('2018-06-20 00:00:00'),\n",
       " Timestamp('2018-06-21 00:00:00'),\n",
       " Timestamp('2018-06-25 00:00:00'),\n",
       " Timestamp('2018-06-27 00:00:00'),\n",
       " Timestamp('2018-07-09 00:00:00'),\n",
       " Timestamp('2018-07-12 00:00:00'),\n",
       " Timestamp('2018-07-16 00:00:00'),\n",
       " Timestamp('2018-07-17 00:00:00'),\n",
       " Timestamp('2018-07-18 00:00:00'),\n",
       " Timestamp('2018-07-20 00:00:00'),\n",
       " Timestamp('2018-07-24 00:00:00'),\n",
       " Timestamp('2018-07-31 00:00:00'),\n",
       " Timestamp('2018-08-01 00:00:00'),\n",
       " Timestamp('2018-08-02 00:00:00'),\n",
       " Timestamp('2018-08-06 00:00:00'),\n",
       " Timestamp('2018-08-08 00:00:00'),\n",
       " Timestamp('2018-08-09 00:00:00'),\n",
       " Timestamp('2018-08-10 00:00:00'),\n",
       " Timestamp('2018-08-14 00:00:00'),\n",
       " Timestamp('2018-08-16 00:00:00'),\n",
       " Timestamp('2018-08-17 00:00:00'),\n",
       " Timestamp('2018-08-20 00:00:00'),\n",
       " Timestamp('2018-08-21 00:00:00'),\n",
       " Timestamp('2018-08-22 00:00:00'),\n",
       " Timestamp('2018-08-23 00:00:00'),\n",
       " Timestamp('2018-08-28 00:00:00'),\n",
       " Timestamp('2018-08-31 00:00:00'),\n",
       " Timestamp('2018-09-11 00:00:00'),\n",
       " Timestamp('2018-09-17 00:00:00'),\n",
       " Timestamp('2018-09-18 00:00:00'),\n",
       " Timestamp('2018-09-27 00:00:00'),\n",
       " Timestamp('2018-10-02 00:00:00'),\n",
       " Timestamp('2018-10-17 00:00:00'),\n",
       " Timestamp('2018-10-18 00:00:00'),\n",
       " Timestamp('2018-11-09 00:00:00'),\n",
       " Timestamp('2018-11-19 00:00:00'),\n",
       " Timestamp('2018-11-21 00:00:00'),\n",
       " Timestamp('2018-11-26 00:00:00')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differ_date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "earning_data.drop(differ_date2, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 214\n"
     ]
    }
   ],
   "source": [
    "print(len(data_filter_freq),len(earning_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!!/sf</th>\n",
       "      <th>!/sf</th>\n",
       "      <th>........................./se</th>\n",
       "      <th>......................../se</th>\n",
       "      <th>......................./se</th>\n",
       "      <th>....................../se</th>\n",
       "      <th>...................../se</th>\n",
       "      <th>..................../se</th>\n",
       "      <th>.................../se</th>\n",
       "      <th>................../se</th>\n",
       "      <th>...</th>\n",
       "      <th>홀딩/nng</th>\n",
       "      <th>홀딩스/nng</th>\n",
       "      <th>확보/nng</th>\n",
       "      <th>확인/nng</th>\n",
       "      <th>환율/nng</th>\n",
       "      <th>회사/nng</th>\n",
       "      <th>회장/nng</th>\n",
       "      <th>후/nng</th>\n",
       "      <th>휴맥/nng</th>\n",
       "      <th>힘/nng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-12</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-04</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-18</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-23</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-22</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            !!/sf  !/sf  ........................./se  \\\n",
       "date                                                    \n",
       "2017-06-08    0.0   0.0                           0.0   \n",
       "2017-06-09    0.0   0.0                           0.0   \n",
       "2017-06-13    0.0   0.0                           0.0   \n",
       "2017-06-16    0.0   0.0                           0.0   \n",
       "2017-06-23    0.0   0.0                           0.0   \n",
       "2017-06-30   -0.0   0.0                          -0.0   \n",
       "2017-07-04    0.0   0.0                           0.0   \n",
       "2017-07-12    0.0   0.0                           0.0   \n",
       "2017-07-13    0.0   1.0                           0.0   \n",
       "2017-07-18    0.0   0.0                           0.0   \n",
       "2017-07-19    0.0   3.0                           0.0   \n",
       "2017-07-20    0.0   0.0                           0.0   \n",
       "2017-07-21    0.0   0.0                           0.0   \n",
       "2017-07-24    0.0   1.0                           0.0   \n",
       "2017-07-27    0.0   0.0                           0.0   \n",
       "2017-08-02    0.0   2.0                           0.0   \n",
       "2017-08-03    0.0   0.0                           0.0   \n",
       "2017-08-04    0.0   0.0                           0.0   \n",
       "2017-08-08    0.0   0.0                           0.0   \n",
       "2017-08-09    0.0   0.0                           0.0   \n",
       "2017-08-11    0.0   1.0                           0.0   \n",
       "2017-08-22    0.0   0.0                           0.0   \n",
       "2017-08-30    0.0   0.0                           0.0   \n",
       "2017-09-01    0.0   0.0                           0.0   \n",
       "2017-09-06    0.0   0.0                           0.0   \n",
       "2017-09-07    0.0   0.0                           0.0   \n",
       "2017-09-15    0.0   0.0                           0.0   \n",
       "2017-09-19    0.0   0.0                           0.0   \n",
       "2017-09-27    0.0   0.0                           0.0   \n",
       "2017-09-28    0.0   1.0                           0.0   \n",
       "...           ...   ...                           ...   \n",
       "2018-11-07    0.0   0.0                           0.0   \n",
       "2018-11-08    0.0   0.0                           0.0   \n",
       "2018-11-13    1.0   4.0                           0.0   \n",
       "2018-11-14    0.0   0.0                           0.0   \n",
       "2018-11-15    1.0   1.0                           0.0   \n",
       "2018-11-16    0.0   0.0                           0.0   \n",
       "2018-11-20    0.0   0.0                           0.0   \n",
       "2018-11-22    0.0   0.0                           0.0   \n",
       "2018-11-23    0.0   0.0                           0.0   \n",
       "2018-11-27    0.0   0.0                           0.0   \n",
       "2018-11-28    0.0   0.0                           0.0   \n",
       "2018-11-29    0.0   0.0                           0.0   \n",
       "2018-11-30    0.0   0.0                           0.0   \n",
       "2017-06-12   -0.0  -0.0                          -0.0   \n",
       "2017-06-19   -0.0  -0.0                          -0.0   \n",
       "2017-07-17   -0.0  -0.0                          -0.0   \n",
       "2017-09-04   -0.0   0.0                          -0.0   \n",
       "2017-12-18   -0.0  -0.0                          -0.0   \n",
       "2018-02-26   -0.0  -0.0                          -0.0   \n",
       "2018-03-19   -0.0  -0.0                          -0.0   \n",
       "2018-04-30   -0.0  -0.0                          -0.0   \n",
       "2018-06-04   -0.0  -0.0                          -0.0   \n",
       "2018-06-07   -0.0  -0.0                          -0.0   \n",
       "2018-06-11   -0.0  -0.0                           1.0   \n",
       "2018-07-02   -0.0  -0.0                          -0.0   \n",
       "2018-07-23   -0.0   0.0                          -0.0   \n",
       "2018-07-30   -0.0  -0.0                          -0.0   \n",
       "2018-10-01    0.0  -0.0                          -0.0   \n",
       "2018-10-22   -0.0  -0.0                          -0.0   \n",
       "2018-11-12   -0.0  -0.0                          -0.0   \n",
       "\n",
       "            ......................../se  ......................./se  \\\n",
       "date                                                                  \n",
       "2017-06-08                          0.0                         0.0   \n",
       "2017-06-09                          0.0                         0.0   \n",
       "2017-06-13                          0.0                         0.0   \n",
       "2017-06-16                          0.0                         0.0   \n",
       "2017-06-23                          0.0                         0.0   \n",
       "2017-06-30                         -0.0                        -0.0   \n",
       "2017-07-04                          0.0                         0.0   \n",
       "2017-07-12                          0.0                         0.0   \n",
       "2017-07-13                          0.0                         0.0   \n",
       "2017-07-18                          0.0                         0.0   \n",
       "2017-07-19                          0.0                         0.0   \n",
       "2017-07-20                          0.0                         0.0   \n",
       "2017-07-21                          0.0                         0.0   \n",
       "2017-07-24                          0.0                         0.0   \n",
       "2017-07-27                          0.0                         0.0   \n",
       "2017-08-02                          0.0                         0.0   \n",
       "2017-08-03                          0.0                         0.0   \n",
       "2017-08-04                          0.0                         0.0   \n",
       "2017-08-08                          0.0                         0.0   \n",
       "2017-08-09                          0.0                         0.0   \n",
       "2017-08-11                          0.0                         0.0   \n",
       "2017-08-22                          0.0                         0.0   \n",
       "2017-08-30                          0.0                         0.0   \n",
       "2017-09-01                          0.0                         0.0   \n",
       "2017-09-06                          0.0                         0.0   \n",
       "2017-09-07                          0.0                         0.0   \n",
       "2017-09-15                          0.0                         0.0   \n",
       "2017-09-19                          0.0                         0.0   \n",
       "2017-09-27                          0.0                         0.0   \n",
       "2017-09-28                          0.0                         0.0   \n",
       "...                                 ...                         ...   \n",
       "2018-11-07                          0.0                         0.0   \n",
       "2018-11-08                          0.0                         0.0   \n",
       "2018-11-13                          0.0                         0.0   \n",
       "2018-11-14                          0.0                         0.0   \n",
       "2018-11-15                          0.0                         0.0   \n",
       "2018-11-16                          0.0                         0.0   \n",
       "2018-11-20                          0.0                         0.0   \n",
       "2018-11-22                          0.0                         0.0   \n",
       "2018-11-23                          0.0                         0.0   \n",
       "2018-11-27                          0.0                         0.0   \n",
       "2018-11-28                          0.0                         0.0   \n",
       "2018-11-29                          0.0                         0.0   \n",
       "2018-11-30                          0.0                         0.0   \n",
       "2017-06-12                         -0.0                        -0.0   \n",
       "2017-06-19                         -0.0                        -0.0   \n",
       "2017-07-17                         -0.0                        -0.0   \n",
       "2017-09-04                         -0.0                        -0.0   \n",
       "2017-12-18                         -0.0                        -0.0   \n",
       "2018-02-26                         -0.0                        -0.0   \n",
       "2018-03-19                         -0.0                        -0.0   \n",
       "2018-04-30                         -0.0                        -0.0   \n",
       "2018-06-04                         -0.0                        -0.0   \n",
       "2018-06-07                         -0.0                        -0.0   \n",
       "2018-06-11                          0.0                        -0.0   \n",
       "2018-07-02                         -0.0                        -0.0   \n",
       "2018-07-23                         -0.0                        -0.0   \n",
       "2018-07-30                         -0.0                        -0.0   \n",
       "2018-10-01                         -0.0                        -0.0   \n",
       "2018-10-22                         -0.0                        -0.0   \n",
       "2018-11-12                         -0.0                        -0.0   \n",
       "\n",
       "            ....................../se  ...................../se  \\\n",
       "date                                                              \n",
       "2017-06-08                        0.0                       0.0   \n",
       "2017-06-09                        0.0                       0.0   \n",
       "2017-06-13                        0.0                       0.0   \n",
       "2017-06-16                        0.0                       0.0   \n",
       "2017-06-23                        0.0                       0.0   \n",
       "2017-06-30                       -0.0                      -0.0   \n",
       "2017-07-04                        0.0                       0.0   \n",
       "2017-07-12                        0.0                       0.0   \n",
       "2017-07-13                        0.0                       0.0   \n",
       "2017-07-18                        0.0                       0.0   \n",
       "2017-07-19                        0.0                       0.0   \n",
       "2017-07-20                        0.0                       0.0   \n",
       "2017-07-21                        0.0                       0.0   \n",
       "2017-07-24                        0.0                       0.0   \n",
       "2017-07-27                        0.0                       0.0   \n",
       "2017-08-02                        0.0                       0.0   \n",
       "2017-08-03                        0.0                       0.0   \n",
       "2017-08-04                        0.0                       0.0   \n",
       "2017-08-08                        0.0                       0.0   \n",
       "2017-08-09                        0.0                       0.0   \n",
       "2017-08-11                        0.0                       0.0   \n",
       "2017-08-22                        0.0                       0.0   \n",
       "2017-08-30                        0.0                       0.0   \n",
       "2017-09-01                        0.0                       0.0   \n",
       "2017-09-06                        0.0                       0.0   \n",
       "2017-09-07                        0.0                       0.0   \n",
       "2017-09-15                        0.0                       0.0   \n",
       "2017-09-19                        0.0                       0.0   \n",
       "2017-09-27                        0.0                       0.0   \n",
       "2017-09-28                        0.0                       0.0   \n",
       "...                               ...                       ...   \n",
       "2018-11-07                        0.0                       0.0   \n",
       "2018-11-08                        0.0                       0.0   \n",
       "2018-11-13                        0.0                       0.0   \n",
       "2018-11-14                        0.0                       0.0   \n",
       "2018-11-15                        0.0                       0.0   \n",
       "2018-11-16                        0.0                       0.0   \n",
       "2018-11-20                        0.0                       0.0   \n",
       "2018-11-22                        0.0                       0.0   \n",
       "2018-11-23                        0.0                       0.0   \n",
       "2018-11-27                        0.0                       0.0   \n",
       "2018-11-28                        0.0                       0.0   \n",
       "2018-11-29                        0.0                       0.0   \n",
       "2018-11-30                        0.0                       0.0   \n",
       "2017-06-12                       -0.0                      -0.0   \n",
       "2017-06-19                       -0.0                      -0.0   \n",
       "2017-07-17                       -0.0                      -0.0   \n",
       "2017-09-04                       -0.0                      -0.0   \n",
       "2017-12-18                       -0.0                      -0.0   \n",
       "2018-02-26                       -0.0                      -0.0   \n",
       "2018-03-19                       -0.0                      -0.0   \n",
       "2018-04-30                       -0.0                      -0.0   \n",
       "2018-06-04                       -0.0                       0.0   \n",
       "2018-06-07                       -0.0                      -0.0   \n",
       "2018-06-11                        0.0                       1.0   \n",
       "2018-07-02                       -0.0                      -0.0   \n",
       "2018-07-23                       -0.0                      -0.0   \n",
       "2018-07-30                       -0.0                      -0.0   \n",
       "2018-10-01                       -0.0                      -0.0   \n",
       "2018-10-22                       -0.0                      -0.0   \n",
       "2018-11-12                       -0.0                      -0.0   \n",
       "\n",
       "            ..................../se  .................../se  \\\n",
       "date                                                          \n",
       "2017-06-08                      0.0                     0.0   \n",
       "2017-06-09                      0.0                     0.0   \n",
       "2017-06-13                      0.0                     0.0   \n",
       "2017-06-16                      0.0                     0.0   \n",
       "2017-06-23                      0.0                     0.0   \n",
       "2017-06-30                     -0.0                    -0.0   \n",
       "2017-07-04                      0.0                     0.0   \n",
       "2017-07-12                      0.0                     0.0   \n",
       "2017-07-13                      0.0                     0.0   \n",
       "2017-07-18                      0.0                     0.0   \n",
       "2017-07-19                      0.0                     0.0   \n",
       "2017-07-20                      0.0                     0.0   \n",
       "2017-07-21                      0.0                     0.0   \n",
       "2017-07-24                      0.0                     0.0   \n",
       "2017-07-27                      0.0                     0.0   \n",
       "2017-08-02                      0.0                     0.0   \n",
       "2017-08-03                      0.0                     0.0   \n",
       "2017-08-04                      0.0                     0.0   \n",
       "2017-08-08                      0.0                     0.0   \n",
       "2017-08-09                      0.0                     0.0   \n",
       "2017-08-11                      0.0                     0.0   \n",
       "2017-08-22                      0.0                     0.0   \n",
       "2017-08-30                      0.0                     0.0   \n",
       "2017-09-01                      0.0                     0.0   \n",
       "2017-09-06                      0.0                     0.0   \n",
       "2017-09-07                      0.0                     0.0   \n",
       "2017-09-15                      0.0                     0.0   \n",
       "2017-09-19                      0.0                     0.0   \n",
       "2017-09-27                      0.0                     0.0   \n",
       "2017-09-28                      0.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "2018-11-07                      0.0                     0.0   \n",
       "2018-11-08                      0.0                     0.0   \n",
       "2018-11-13                      0.0                     0.0   \n",
       "2018-11-14                      0.0                     0.0   \n",
       "2018-11-15                      0.0                     0.0   \n",
       "2018-11-16                      0.0                     0.0   \n",
       "2018-11-20                      0.0                     0.0   \n",
       "2018-11-22                      0.0                     0.0   \n",
       "2018-11-23                      0.0                     0.0   \n",
       "2018-11-27                      0.0                     0.0   \n",
       "2018-11-28                      0.0                     0.0   \n",
       "2018-11-29                      0.0                     0.0   \n",
       "2018-11-30                      0.0                     0.0   \n",
       "2017-06-12                     -0.0                    -0.0   \n",
       "2017-06-19                     -0.0                    -0.0   \n",
       "2017-07-17                     -0.0                    -0.0   \n",
       "2017-09-04                     -0.0                    -0.0   \n",
       "2017-12-18                     -0.0                    -0.0   \n",
       "2018-02-26                     -0.0                    -0.0   \n",
       "2018-03-19                     -0.0                    -0.0   \n",
       "2018-04-30                     -0.0                    -0.0   \n",
       "2018-06-04                      0.0                    -0.0   \n",
       "2018-06-07                     -0.0                    -0.0   \n",
       "2018-06-11                      0.0                     0.0   \n",
       "2018-07-02                     -0.0                    -0.0   \n",
       "2018-07-23                     -0.0                    -0.0   \n",
       "2018-07-30                     -0.0                    -0.0   \n",
       "2018-10-01                     -0.0                    -0.0   \n",
       "2018-10-22                     -0.0                    -0.0   \n",
       "2018-11-12                     -0.0                    -0.0   \n",
       "\n",
       "            ................../se  ...    홀딩/nng  홀딩스/nng  확보/nng  확인/nng  \\\n",
       "date                               ...                                      \n",
       "2017-06-08                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-09                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-13                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-16                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-23                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-30                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2017-07-04                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-12                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-13                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-18                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-19                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-20                    0.0  ...       0.0      0.0     0.0     1.0   \n",
       "2017-07-21                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-24                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-07-27                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-02                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-03                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-04                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-08                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-09                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-11                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-22                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-08-30                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-01                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-06                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-07                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-15                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-19                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-27                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-09-28                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "...                           ...  ...       ...      ...     ...     ...   \n",
       "2018-11-07                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-08                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-13                    0.0  ...       0.0      0.0     0.0    10.0   \n",
       "2018-11-14                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-15                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-16                    0.0  ...       0.0      0.0     0.0     1.0   \n",
       "2018-11-20                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-22                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-23                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-27                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-28                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-29                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2018-11-30                    0.0  ...       0.0      0.0     0.0     0.0   \n",
       "2017-06-12                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2017-06-19                   -0.0  ...      -0.0     -0.0    -0.0     0.0   \n",
       "2017-07-17                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2017-09-04                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2017-12-18                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-02-26                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-03-19                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-04-30                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-06-04                    1.0  ...      -0.0     -0.0    -0.0     0.0   \n",
       "2018-06-07                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-06-11                    1.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-07-02                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-07-23                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-07-30                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-10-01                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-10-22                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "2018-11-12                   -0.0  ...      -0.0     -0.0    -0.0    -0.0   \n",
       "\n",
       "            환율/nng  회사/nng  회장/nng  후/nng  휴맥/nng  힘/nng  \n",
       "date                                                      \n",
       "2017-06-08     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-06-09     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-06-13     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-06-16     0.0     0.0     0.0    1.0     0.0    0.0  \n",
       "2017-06-23     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-06-30    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2017-07-04     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-12     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-13     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-18     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-19     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-20     0.0     2.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-21     0.0     1.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-24     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-07-27     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-02     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-03     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-04     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-08     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-09     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-11     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-22     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-08-30     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-01     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-06     0.0     1.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-07     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-15     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-19     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-27     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-09-28     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "...            ...     ...     ...    ...     ...    ...  \n",
       "2018-11-07     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-08     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-13     0.0     5.0     0.0    2.0     0.0    1.0  \n",
       "2018-11-14     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-15     0.0     0.0     0.0    6.0     0.0    0.0  \n",
       "2018-11-16    13.0     1.0     0.0    7.0     0.0    0.0  \n",
       "2018-11-20     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-22     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-23     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-27     0.0     1.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-28     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-29     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2018-11-30     0.0     0.0     0.0    0.0     0.0    0.0  \n",
       "2017-06-12    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2017-06-19    -0.0    -0.0    -0.0    0.0    -0.0    0.0  \n",
       "2017-07-17    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2017-09-04    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2017-12-18    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-02-26    -0.0    -0.0    -0.0   -0.0    -0.0    0.0  \n",
       "2018-03-19    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-04-30    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-06-04    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-06-07    -0.0     0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-06-11    -0.0     0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-07-02    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-07-23    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-07-30    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "2018-10-01    -0.0    -0.0    -0.0    1.0    -0.0   -0.0  \n",
       "2018-10-22    -0.0    -0.0    -0.0   -0.0    -0.0    0.0  \n",
       "2018-11-12    -0.0    -0.0    -0.0   -0.0    -0.0   -0.0  \n",
       "\n",
       "[214 rows x 468 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감성 사전을 크게 두가지로 만들 것이다.\n",
    "1. 분모를 해당 형태소 빈도 \n",
    "2. 분모를 긍정글의 갯수/ 부정글의 갯수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 분모를 해당 형태소 빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_freq_copy = data_filter_freq\n",
    "plus_dataframe1 = pd.DataFrame(columns=data_filter_freq_copy.columns)\n",
    "minus_dataframe1 = pd.DataFrame(columns=data_filter_freq_copy.columns)\n",
    "plus_dict1 = pd.Series([])\n",
    "minus_dict1 = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for idx in range(data_filter_freq.shape[0]):    \n",
    "    #print(idx)\n",
    "    if earning_data.iloc[idx]==1:\n",
    "        #print('data_filter_freq_copy.iloc[idx,:]* 1:',data_filter_freq_copy.iloc[idx,:]* 1)\n",
    "        plus_dataframe1= plus_dataframe1.append(data_filter_freq_copy.iloc[idx,:]* 1)   \n",
    "        \n",
    "    elif earning_data.iloc[idx]==0:\n",
    "        minus_dataframe1 = minus_dataframe1.append(data_filter_freq_copy.iloc[idx,:]* -1)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_plus1 = plus_dataframe1.sum(axis=0)\n",
    "sum_filter_freq = data_filter_freq_copy.sum(axis=0)\n",
    "for idx in range(len(sum_plus1)):\n",
    "    plus_dict1 = plus_dict1.append(pd.Series(sum_plus1[idx]/sum_filter_freq[idx],index=[sum_plus1.index[idx]]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "답변/nng            1.000000\n",
       "발생/nng            0.956522\n",
       "미국/nnp            0.937500\n",
       "기금/nng            0.906250\n",
       "운용/nng            0.880952\n",
       "전쟁/nng            0.875000\n",
       "v/sl              0.869565\n",
       "확보/nng            0.843750\n",
       "영향/nng            0.826087\n",
       "곳/nng             0.815789\n",
       "m/sl              0.812500\n",
       "수수료/nng           0.810811\n",
       "전화/nng            0.807692\n",
       "이득/nng            0.806452\n",
       "공시/nng            0.800000\n",
       "cj/sl             0.800000\n",
       "빌리/vv             0.772727\n",
       "피/nng             0.769231\n",
       "읽/vv              0.764706\n",
       "명부/nng            0.758621\n",
       "선택/nng            0.758621\n",
       "자산/nng            0.754717\n",
       "합병/nng            0.750000\n",
       "기/nng             0.741935\n",
       ".........../se    0.735849\n",
       "회장/nng            0.731959\n",
       "배당금/nng           0.720000\n",
       "매/nng             0.714286\n",
       "시점/nng            0.710526\n",
       "급락/nng            0.708333\n",
       "                    ...   \n",
       "위/nnb             0.333333\n",
       "폭락/nng            0.325581\n",
       "세계/nng            0.325000\n",
       "실적/nng            0.324324\n",
       "www/sl            0.320755\n",
       "최근/nng            0.312500\n",
       "이제/mag            0.307692\n",
       "예측/nng            0.304348\n",
       "들어가/vv            0.303030\n",
       "재산/nng            0.300000\n",
       "금융/nng            0.290323\n",
       "성장/nng            0.280000\n",
       "명/nnb             0.275862\n",
       "mbk/sl            0.274510\n",
       "개선/nng            0.263158\n",
       "go/sl             0.250000\n",
       "연대/nng            0.250000\n",
       "president/sl      0.250000\n",
       "기업/nng            0.247423\n",
       "금지/nng            0.233333\n",
       "petitions/sl      0.229167\n",
       "대/xpn             0.228571\n",
       "청와대/nnp           0.222222\n",
       "경제/nng            0.194030\n",
       "위기/nng            0.185185\n",
       "ㅋ/nng             0.179487\n",
       "ㅋ/ic              0.176471\n",
       "정수기/nng           0.156250\n",
       "ㅋ/mag             0.153846\n",
       "환율/nng            0.034483\n",
       "Length: 468, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_dict1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_minus1 = minus_dataframe1.sum(axis=0)\n",
    "sum_filter_freq = data_filter_freq_copy.sum(axis=0)\n",
    "for idx in range(len(sum_minus1)):\n",
    "    minus_dict1 = minus_dict1.append(pd.Series(sum_minus1[idx]/sum_filter_freq[idx],index=[sum_minus1.index[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "환율/nng           -0.965517\n",
       "ㅋ/mag            -0.846154\n",
       "정수기/nng          -0.843750\n",
       "ㅋ/ic             -0.823529\n",
       "ㅋ/nng            -0.820513\n",
       "위기/nng           -0.814815\n",
       "경제/nng           -0.805970\n",
       "청와대/nnp          -0.777778\n",
       "대/xpn            -0.771429\n",
       "petitions/sl     -0.770833\n",
       "금지/nng           -0.766667\n",
       "기업/nng           -0.752577\n",
       "president/sl     -0.750000\n",
       "연대/nng           -0.750000\n",
       "go/sl            -0.750000\n",
       "개선/nng           -0.736842\n",
       "mbk/sl           -0.725490\n",
       "명/nnb            -0.724138\n",
       "성장/nng           -0.720000\n",
       "금융/nng           -0.709677\n",
       "재산/nng           -0.700000\n",
       "들어가/vv           -0.696970\n",
       "예측/nng           -0.695652\n",
       "이제/mag           -0.692308\n",
       "최근/nng           -0.687500\n",
       "www/sl           -0.679245\n",
       "실적/nng           -0.675676\n",
       "세계/nng           -0.675000\n",
       "폭락/nng           -0.674419\n",
       "위/nnb            -0.666667\n",
       "                    ...   \n",
       "급락/nng           -0.291667\n",
       "시점/nng           -0.289474\n",
       "매/nng            -0.285714\n",
       "배당금/nng          -0.280000\n",
       "회장/nng           -0.268041\n",
       ".........../se   -0.264151\n",
       "기/nng            -0.258065\n",
       "합병/nng           -0.250000\n",
       "자산/nng           -0.245283\n",
       "선택/nng           -0.241379\n",
       "명부/nng           -0.241379\n",
       "읽/vv             -0.235294\n",
       "피/nng            -0.230769\n",
       "빌리/vv            -0.227273\n",
       "cj/sl            -0.200000\n",
       "공시/nng           -0.200000\n",
       "이득/nng           -0.193548\n",
       "전화/nng           -0.192308\n",
       "수수료/nng          -0.189189\n",
       "m/sl             -0.187500\n",
       "곳/nng            -0.184211\n",
       "영향/nng           -0.173913\n",
       "확보/nng           -0.156250\n",
       "v/sl             -0.130435\n",
       "전쟁/nng           -0.125000\n",
       "운용/nng           -0.119048\n",
       "기금/nng           -0.093750\n",
       "미국/nnp           -0.062500\n",
       "발생/nng           -0.043478\n",
       "답변/nng            0.000000\n",
       "Length: 468, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minus_dict1.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimental_score1 = (plus_dict1.sort_values(ascending=False)+ minus_dict1.sort_values(ascending=False)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "답변/nng            1.000000\n",
       "발생/nng            0.913043\n",
       "미국/nnp            0.875000\n",
       "기금/nng            0.812500\n",
       "운용/nng            0.761905\n",
       "전쟁/nng            0.750000\n",
       "v/sl              0.739130\n",
       "확보/nng            0.687500\n",
       "영향/nng            0.652174\n",
       "곳/nng             0.631579\n",
       "m/sl              0.625000\n",
       "수수료/nng           0.621622\n",
       "전화/nng            0.615385\n",
       "이득/nng            0.612903\n",
       "공시/nng            0.600000\n",
       "cj/sl             0.600000\n",
       "빌리/vv             0.545455\n",
       "피/nng             0.538462\n",
       "읽/vv              0.529412\n",
       "명부/nng            0.517241\n",
       "선택/nng            0.517241\n",
       "자산/nng            0.509434\n",
       "합병/nng            0.500000\n",
       "기/nng             0.483871\n",
       ".........../se    0.471698\n",
       "회장/nng            0.463918\n",
       "배당금/nng           0.440000\n",
       "매/nng             0.428571\n",
       "시점/nng            0.421053\n",
       "급락/nng            0.416667\n",
       "                    ...   \n",
       "일부/nng           -0.333333\n",
       "폭락/nng           -0.348837\n",
       "세계/nng           -0.350000\n",
       "실적/nng           -0.351351\n",
       "www/sl           -0.358491\n",
       "최근/nng           -0.375000\n",
       "이제/mag           -0.384615\n",
       "예측/nng           -0.391304\n",
       "들어가/vv           -0.393939\n",
       "재산/nng           -0.400000\n",
       "금융/nng           -0.419355\n",
       "성장/nng           -0.440000\n",
       "명/nnb            -0.448276\n",
       "mbk/sl           -0.450980\n",
       "개선/nng           -0.473684\n",
       "go/sl            -0.500000\n",
       "연대/nng           -0.500000\n",
       "president/sl     -0.500000\n",
       "기업/nng           -0.505155\n",
       "금지/nng           -0.533333\n",
       "petitions/sl     -0.541667\n",
       "대/xpn            -0.542857\n",
       "청와대/nnp          -0.555556\n",
       "경제/nng           -0.611940\n",
       "위기/nng           -0.629630\n",
       "ㅋ/nng            -0.641026\n",
       "ㅋ/ic             -0.647059\n",
       "정수기/nng          -0.687500\n",
       "ㅋ/mag            -0.692308\n",
       "환율/nng           -0.931034\n",
       "Length: 468, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimental_score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 분모를 긍정글의 갯수/ 부정글의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_freq_copy = data_filter_freq\n",
    "plus_dataframe2 = pd.DataFrame(columns=data_filter_freq_copy.columns)\n",
    "minus_dataframe2 = pd.DataFrame(columns=data_filter_freq_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_freq_copy = data_filter_freq\n",
    "plus_dataframe2 = pd.DataFrame(columns=data_filter_freq_copy.columns)\n",
    "minus_dataframe2 = pd.DataFrame(columns=data_filter_freq_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for idx in range(data_filter_freq.shape[0]):    \n",
    "    #print(idx)\n",
    "    if earning_data.iloc[idx]==1:\n",
    "        #print('data_filter_freq_copy.iloc[idx,:]* 1:',data_filter_freq_copy.iloc[idx,:]* 1)\n",
    "        plus_dataframe2= plus_dataframe1.append(data_filter_freq_copy.iloc[idx,:]* 1)   \n",
    "        \n",
    "    elif earning_data.iloc[idx]==0:\n",
    "        minus_dataframe2 = minus_dataframe1.append(data_filter_freq_copy.iloc[idx,:]* -1)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_dict2=minus_dataframe2.mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_dict2=plus_dataframe2.mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimental_score2 = (plus_dataframe2.mean(axis=0).sort_values(ascending=False)+ minus_dataframe2.mean(axis=0).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "!!/sf                          -0.036552\n",
       "!/sf                           -0.402414\n",
       "........................./se   -0.050690\n",
       "......................../se    -0.023448\n",
       "......................./se     -0.026552\n",
       "....................../se      -0.012069\n",
       "...................../se       -0.002069\n",
       "..................../se         0.009655\n",
       ".................../se          0.001379\n",
       "................../se           0.017241\n",
       "................./se           -0.009310\n",
       "................/se            -0.024828\n",
       ".............../se              0.125172\n",
       "............../se               0.077586\n",
       "............./se                0.242759\n",
       "............/se                 0.183448\n",
       ".........../se                  0.392414\n",
       "........../se                   0.260000\n",
       "........./se                    0.048621\n",
       "......../se                     0.020690\n",
       "......./se                      0.104138\n",
       "....../se                       0.093793\n",
       "...../se                        0.055517\n",
       "..../se                         0.106552\n",
       ".../se                         -0.077931\n",
       "../se                          -0.361724\n",
       "../sf                          -0.124828\n",
       "./se                           -0.193103\n",
       "?/sf                           -1.121724\n",
       "cj/sl                           0.195862\n",
       "                                  ...   \n",
       "팔/vv                           -0.176897\n",
       "펀드/nng                         -0.016552\n",
       "평가/nng                          0.065172\n",
       "포트폴리오/nng                      -0.025172\n",
       "폭락/nng                         -0.169310\n",
       "폭탄/nng                         -0.056552\n",
       "피/nng                           0.112414\n",
       "피하/vv                           0.037931\n",
       "필요/nng                         -0.003103\n",
       "하/vv                           -0.811724\n",
       "하락/nng                         -0.283448\n",
       "하루/nng                         -0.079655\n",
       "한/mm                            0.024828\n",
       "한국/nnp                         -0.009310\n",
       "함께/mag                         -0.065172\n",
       "합병/nng                          0.095172\n",
       "해외/nng                         -0.011034\n",
       "현금/nng                          0.042759\n",
       "현재/mag                          0.034828\n",
       "혹시/mag                          0.027931\n",
       "홀딩/nng                          0.037931\n",
       "홀딩스/nng                         0.050690\n",
       "확보/nng                          0.182759\n",
       "확인/nng                          0.124483\n",
       "환율/nng                         -0.271379\n",
       "회사/nng                         -0.047586\n",
       "회장/nng                          0.352069\n",
       "후/nng                          -0.039310\n",
       "휴맥/nng                         -0.025172\n",
       "힘/nng                          -0.002414\n",
       "Length: 468, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimental_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary 초기화\n",
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "\n",
    "y = np.array(earning_data_ori)\n",
    "#y = np.array(earning_data)\n",
    "#y = np.array([labeling(label) for label in earning_data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = {'상승':[(sum(y)/len(y))], '하락':[(1-sum(y)/len(y))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'상승': [0.5373831775700935], '하락': [0.46261682242990654]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame.from_dict(y_dict)\n",
    "plt.bar(['상승','하락'],[(sum(y)/len(y)),(1-sum(y)/len(y))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수를 계산한다. \n",
    "X_train_raw, X_test_raw,y_train,y_test= train_test_split(data_filter_freq,y, test_size=0.33, shuffle=False)\n",
    "#X_train_index, X_test_index = train_test_split(earning_data_ori,test_size=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_column_freq = data_filter_freq.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(sum(y_test)/len(y_test)),(1-sum(y_test)/len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(sum(y_train)/len(y_train)),(1-sum(y_train)/len(y_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점수를 하나로만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if X_train_raw.iloc[0,:].sum() == 0:\n",
    "#     result = 0\n",
    "#X_train_raw.iloc[0,:] != 0\n",
    "#값이 존재하는 형태소 추출\n",
    "X_train = pd.Series()\n",
    "for train_idx in range(X_train_raw.shape[0]):\n",
    "    #해당번째 열 추출\n",
    "    train_iloc = X_train_raw.iloc[train_idx,:]\n",
    "    #값이존재하는 형태소 추출\n",
    "    select_pos = train_iloc.index[train_iloc != 0]\n",
    "    # 그 형태소의 인덱스\n",
    "    select_idx=[]\n",
    "    for pos_idx, pos_element in enumerate(select_pos):\n",
    "        for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "            if column_element == pos_element:\n",
    "                select_idx.append(column_idx)\n",
    "    # 빈도\n",
    "    select_series = X_train_raw.iloc[train_idx,select_idx]    \n",
    "    #(점수 * 빈도)총합/ 빈도 \n",
    "    \n",
    "    X_train[train_iloc.name]=(sentimental_score1[select_pos] * select_series).mean()\n",
    "X_train.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#X_train_raw.iloc[0,:]\n",
    "\n",
    "\n",
    "#X_train_raw.loc[:,select_pos]\n",
    "    \n",
    "    \n",
    "#X_train_raw.iloc[0,X_train_raw.iloc[0,:].index[X_train_raw.iloc[0,:] != 0]]\n",
    "#X_train_raw.iloc[0,:] != 0\n",
    "#X_train_raw.iloc[0,X_train_raw.iloc[0,:] != 0]\n",
    "#/X_train_raw.iloc[0,:].sum()\n",
    "# row 마다 감성사전에서 점수를 계산한다 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긍정부정 나눠서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 부정 전처리 함수\n",
    "def train_pos_neg_processing(X_train_raw):\n",
    "    X_train = pd.DataFrame(columns=['긍정','부정'])\n",
    "    for train_idx in range(X_train_raw.shape[0]):\n",
    "        #해당번째 열 추출\n",
    "        train_iloc = X_train_raw.iloc[train_idx,:]\n",
    "        #값이존재하는 형태소 추출\n",
    "        select_pos = train_iloc.index[train_iloc != 0]\n",
    "        # 그 형태소의 인덱스\n",
    "        select_idx=[]\n",
    "        for pos_idx, pos_element in enumerate(select_pos):\n",
    "            for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "                if column_element == pos_element:\n",
    "                    select_idx.append(column_idx)\n",
    "        # 빈도\n",
    "        select_series = X_train_raw.iloc[train_idx,select_idx]    \n",
    "        #(점수 * 빈도)총합/ 빈도 \n",
    "\n",
    "\n",
    "        #plus_dict의 해당 형태소 점수를 뽑아오는 것이 목표이다.\n",
    "        #indexing하면 error뜨고 \n",
    "        #plus_dict에 해당 형태소가 존재하면\n",
    "\n",
    "    #     print(select_pos)\n",
    "    #     print(plus_dict[select_pos].dtype)\n",
    "\n",
    "        plus_pos = []\n",
    "        for value in select_pos:\n",
    "            for element in plus_dict1.index:\n",
    "                if value == element:\n",
    "                    plus_pos.append(element)\n",
    "        plus_idx = []            \n",
    "        for pos_idx, pos_element in enumerate(plus_pos):\n",
    "            for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "                if column_element == pos_element:\n",
    "                    plus_idx.append(column_idx)\n",
    "\n",
    "        minus_pos = []\n",
    "        for value in select_pos:\n",
    "            for element in minus_dict1.index:\n",
    "                if value == element:\n",
    "                    minus_pos.append(element)\n",
    "\n",
    "        minus_idx = []            \n",
    "        for pos_idx, pos_element in enumerate(minus_pos):\n",
    "            for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "                if column_element == pos_element:\n",
    "                    minus_idx.append(column_idx)\n",
    "\n",
    "\n",
    "        pos_freq = X_train_raw.iloc[train_idx,plus_idx]\n",
    "        pos_freq_sum = pos_freq.sum()  \n",
    "        pos_score_dot_freq = np.dot(plus_dict1[plus_pos],X_train_raw.iloc[train_idx,plus_idx])\n",
    "        minus_freq_sum = X_train_raw.iloc[train_idx,minus_idx].sum()\n",
    "        minus_score_dot_freq = np.dot(minus_dict1[minus_pos],X_train_raw.iloc[train_idx,minus_idx])    \n",
    "        X_train = X_train.append(pd.DataFrame([[pos_score_dot_freq/pos_freq_sum,(minus_score_dot_freq/minus_freq_sum)*(-1)]],columns=X_train.columns,index=[pos_freq.name]))    \n",
    "    X_train.fillna(0,inplace=True)\n",
    "    return X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.DataFrame(columns=['긍정','부정'])\n",
    "# for train_idx in range(X_train_raw.shape[0]):\n",
    "#     #해당번째 열 추출\n",
    "#     train_iloc = X_train_raw.iloc[train_idx,:]\n",
    "#     #값이존재하는 형태소 추출\n",
    "#     select_pos = train_iloc.index[train_iloc != 0]\n",
    "#     # 그 형태소의 인덱스\n",
    "#     select_idx=[]\n",
    "#     for pos_idx, pos_element in enumerate(select_pos):\n",
    "#         for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "#             if column_element == pos_element:\n",
    "#                 select_idx.append(column_idx)\n",
    "#     # 빈도\n",
    "#     select_series = X_train_raw.iloc[train_idx,select_idx]    \n",
    "#     #(점수 * 빈도)총합/ 빈도 \n",
    "    \n",
    "    \n",
    "#     #plus_dict의 해당 형태소 점수를 뽑아오는 것이 목표이다.\n",
    "#     #indexing하면 error뜨고 \n",
    "#     #plus_dict에 해당 형태소가 존재하면\n",
    "    \n",
    "# #     print(select_pos)\n",
    "# #     print(plus_dict[select_pos].dtype)\n",
    "    \n",
    "#     plus_pos = []\n",
    "#     for value in select_pos:\n",
    "#         for element in plus_dict1.index:\n",
    "#             if value == element:\n",
    "#                 plus_pos.append(element)\n",
    "#     plus_idx = []            \n",
    "#     for pos_idx, pos_element in enumerate(plus_pos):\n",
    "#         for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "#             if column_element == pos_element:\n",
    "#                 plus_idx.append(column_idx)\n",
    "                \n",
    "#     minus_pos = []\n",
    "#     for value in select_pos:\n",
    "#         for element in minus_dict1.index:\n",
    "#             if value == element:\n",
    "#                 minus_pos.append(element)\n",
    "                \n",
    "#     minus_idx = []            \n",
    "#     for pos_idx, pos_element in enumerate(minus_pos):\n",
    "#         for column_idx,column_element in enumerate(X_train_raw.columns):\n",
    "#             if column_element == pos_element:\n",
    "#                 minus_idx.append(column_idx)\n",
    "    \n",
    "                \n",
    "# #     print('plus_pos,minus_pos',plus_pos,minus_pos)\n",
    "# #     print('plus_idx,minus_idx',plus_idx,minus_idx)\n",
    "#     # t시점의 형태소 빈도 * 그 형태소의 점수 /해당 시점의 형태소의 합\n",
    "#     # 긍정\n",
    "#     # 각 시점의 각 형태소 갯수\n",
    "#     #print(X_train_raw.iloc[train_idx,plus_idx])\n",
    "#     # 각 시점의 형태소 합 \n",
    "#     pos_freq = X_train_raw.iloc[train_idx,plus_idx]\n",
    "#     pos_freq_sum = pos_freq.sum()\n",
    "#     #print(pos_freq_sum)\n",
    "#     pos_score_dot_freq = np.dot(plus_dict1[plus_pos],X_train_raw.iloc[train_idx,plus_idx])\n",
    "#     #print(pos_score_dot_freq)\n",
    "    \n",
    "#     #print(X_train_raw.iloc[train_idx,plus_idx])\n",
    "#     # 각 시점의 형태소 합 \n",
    "#     minus_freq_sum = X_train_raw.iloc[train_idx,minus_idx].sum()\n",
    "#     #print(minus_freq_sum)\n",
    "#     minus_score_dot_freq = np.dot(minus_dict1[minus_pos],X_train_raw.iloc[train_idx,minus_idx])\n",
    "#     #print(minus_score_dot_freq)\n",
    "#     #print(plus_dict1[plus_pos] * X_train_raw.iloc[train_idx,plus_idx]/data_filter_column_freq[plus_pos])\n",
    "#     #print(pd.DataFrame([[pos_score_dot_freq/pos_freq_sum,minus_score_dot_freq/minus_freq_sum]],columns=X_train.columns,index=[pos_freq.name]))\n",
    "#     X_train = X_train.append(pd.DataFrame([[pos_score_dot_freq/pos_freq_sum,minus_score_dot_freq/minus_freq_sum]],columns=X_train.columns,index=[pos_freq.name]))\n",
    "#     #X_train['부정'].append(minus_dict1[minus_pos] * X_train_raw.iloc[train_idx,minus_idx]/data_filter_column_freq[minus_pos])           \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     #minus_dict에 해당 형태소가 존재하면    \n",
    "    \n",
    "#     #X_train[train_iloc.name,]=(sentimental_score1[select_pos] * select_series).mean()\n",
    "    \n",
    "    \n",
    "# X_train.fillna(0,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_pos_neg_processing(X_train_raw)\n",
    "X_test = train_pos_neg_processing(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "precision_score_result=Counter()\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = (RFC,rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = (SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "\n",
    "\n",
    "#gsExtC = (ExtraTreesClassifier, ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "classifiers.append(SVC(random_state=4000))\n",
    "classifiers.append(RandomForestClassifier(random_state=4000))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=4000))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=4000))\n",
    "\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(penalty='l2',random_state=4000))\n",
    "\n",
    "classifiers.append(XGBClassifier(random_state=4000))\n",
    "classifiers.append(LinearSVC(random_state=4000))\n",
    "classifiers.append(MLPClassifier(random_state=4000))\n",
    "\n",
    "\n",
    "\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())# 튜닝 불가능\n",
    "classifiers_not.append(GaussianNB())\n",
    "classifiers_not.append(MultinomialNB())\n",
    "classifiers_not.append(BernoulliNB())\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "precision_score_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    \n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    \n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "precision_score_result[stock_code]=precision_score_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=['SVC',\n",
    "'Randomforest',\n",
    "'Extratrees',\n",
    "'Gradientboosting',\n",
    "'Kneighbors',\n",
    "'Logistic',\n",
    "'Xgboost',\n",
    "'LinearSVC',\n",
    "'MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = confusion_matrix_result[stock_code][idx]['GridSearchCV']\n",
    "#     confusion_matrix_result[stock_code][idx] = tmp_dict\n",
    "# print(confusion_matrix_result)\n",
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = model_result[stock_code][idx]['GridSearchCV']\n",
    "#     model_result[stock_code][idx] = tmp_dict\n",
    "# print(model_result)\n",
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = train_result[stock_code][idx]['GridSearchCV']\n",
    "#     train_result[stock_code][idx] = tmp_dict\n",
    "# print(train_result)\n",
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = test_result[stock_code][idx]['GridSearchCV']\n",
    "#     test_result[stock_code][idx] = tmp_dict\n",
    "# print(test_result)\n",
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = precision_score_result[stock_code][idx]['GridSearchCV']\n",
    "#     precision_score_result[stock_code][idx] = tmp_dict\n",
    "# print(precision_score_result)     \n",
    "# for idx,element in enumerate(model_list):    \n",
    "#     tmp_dict = {}\n",
    "#     tmp_dict[element] = precision_train_result[stock_code][idx]['GridSearchCV']\n",
    "#     precision_train_result[stock_code][idx] = tmp_dict\n",
    "# print(precision_score_result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in train_accuracy_list:\n",
    "    for key in element.keys():\n",
    "        if key.find('RandomForestClassifier')>=0:\n",
    "            element['RF'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('ExtraTreesClassifier')>=0:        \n",
    "            element['ET'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GradientBoostingClassifier')>=0:        \n",
    "            element['GB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('KNeighborsClassifier')>=0:        \n",
    "            element['KNN'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LogisticRegression')>=0:        \n",
    "            element['LR'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('XGBClassifier')>=0:        \n",
    "            element['XGB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearSVC')>=0:        \n",
    "            element['LSVC'] = element[key]\n",
    "            del element[key]        \n",
    "        if key.find('MLPClassifier')>=0:        \n",
    "            element['MLP'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearDiscriminantAnalysis')>=0:        \n",
    "            element['LDA'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GaussianNB')>=0:        \n",
    "            element['GNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('MultinomialNB')>=0:        \n",
    "            element['MNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('BernoulliNB')>=0:        \n",
    "            element['BNB'] = element[key]\n",
    "            del element[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict=Counter()\n",
    "for element in train_accuracy_list:\n",
    "    train_dict.update(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict= dict(zip(train_dict.keys(),sns.color_palette(\"hls\", len(classifiers)+len(classifiers_not))))\n",
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys=sorted(train_dict,key=lambda x:train_dict[x],reverse=True)\n",
    "train_values=sorted(train_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Train)',fontsize = 20)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.ylim((0.4,1))\n",
    "sns.barplot(train_keys,train_values,palette=[color_dict[key] for key in train_keys]) # 그래프가 바뀌어도 분류기에 대한 색깔이 변치 않기위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in test_accuracy_list:\n",
    "    for key in element.keys():\n",
    "        if key.find('RandomForestClassifier')>=0:\n",
    "            element['RF'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('ExtraTreesClassifier')>=0:        \n",
    "            element['ET'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GradientBoostingClassifier')>=0:        \n",
    "            element['GB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('KNeighborsClassifier')>=0:        \n",
    "            element['KNN'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LogisticRegression')>=0:        \n",
    "            element['LR'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('XGBClassifier')>=0:        \n",
    "            element['XGB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearSVC')>=0:        \n",
    "            element['LSVC'] = element[key]\n",
    "            del element[key]        \n",
    "        if key.find('MLPClassifier')>=0:        \n",
    "            element['MLP'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearDiscriminantAnalysis')>=0:        \n",
    "            element['LDA'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GaussianNB')>=0:        \n",
    "            element['GNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('MultinomialNB')>=0:        \n",
    "            element['MNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('BernoulliNB')>=0:        \n",
    "            element['BNB'] = element[key]\n",
    "            del element[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict=Counter()\n",
    "for element in test_accuracy_list:\n",
    "    test_dict.update(element)\n",
    "test_keys=sorted(test_dict.keys(),key=lambda x:test_dict[x],reverse=True)\n",
    "test_values=sorted(test_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.ylim((0.5,0.7))\n",
    "sns.barplot(test_keys,test_values,palette=[color_dict[key] for key in test_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dict = train_dict - test_dict\n",
    "test_keys=sorted(train_test_dict.keys(),key=lambda x:train_test_dict[x],reverse=True)\n",
    "test_values=sorted(train_test_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Difference(Train,Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "sns.barplot(test_keys,test_values,palette=[color_dict[key] for key in test_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in precision_score_list:\n",
    "    for key in element.keys():\n",
    "        if key.find('RandomForestClassifier')>=0:\n",
    "            element['RF'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('ExtraTreesClassifier')>=0:        \n",
    "            element['ET'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GradientBoostingClassifier')>=0:        \n",
    "            element['GB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('KNeighborsClassifier')>=0:        \n",
    "            element['KNN'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LogisticRegression')>=0:        \n",
    "            element['LR'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('XGBClassifier')>=0:        \n",
    "            element['XGB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearSVC')>=0:        \n",
    "            element['LSVC'] = element[key]\n",
    "            del element[key]        \n",
    "        if key.find('MLPClassifier')>=0:        \n",
    "            element['MLP'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearDiscriminantAnalysis')>=0:        \n",
    "            element['LDA'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GaussianNB')>=0:        \n",
    "            element['GNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('MultinomialNB')>=0:        \n",
    "            element['MNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('BernoulliNB')>=0:        \n",
    "            element['BNB'] = element[key]\n",
    "            del element[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict={}\n",
    "for element in precision_score_list:\n",
    "    precision_score_dict.update(element)\n",
    "precision_score_keys=sorted(precision_score_dict.keys(),key=lambda x:precision_score_dict[x],reverse=True)\n",
    "precision_score_values=sorted(precision_score_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Precision(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(precision_score_keys,precision_score_values,palette=[color_dict[key] for key in precision_score_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling 이전 start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위모델 선정O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape: (143, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV : {'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'n_estimators': 500, 'random_state': 4000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV : {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'n_estimators': 500, 'random_state': 4000}\n",
      "GridSearchCV : {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'max_features': 0.3, 'min_samples_leaf': 200, 'n_estimators': 500, 'random_state': 4000}\n",
      "GridSearchCV : {'n_neighbors': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "precision_score_result=Counter()\n",
    "precision_train_result = Counter()\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "\n",
    "svc_param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state }\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [3, 5, 10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"bootstrap\": [False,True],\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\",'exponential'],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': [200,400,600],\n",
    "              'max_features': [0.3, 0.1], 'random_state':random_state  \n",
    "              }\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [3,4,5,10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': Cs                                   \n",
    "              }\n",
    "\n",
    "lda_param_grid = {'solver' : [\"svd\",'lsqr','eigen'],\n",
    "              'shrinkage ' : ['auto'], 'random_state':random_state \n",
    "              }\n",
    "\n",
    "kneighbor_param_grid = {'n_neighbors':list(range(1,31))}\n",
    "\n",
    "xgboost_param_grid ={\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "     'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "     'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'n_estimators':[100,500,1000,2000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'priors':None, 'random_state':random_state \n",
    "}\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,0.1,1,10,100],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[1000,2000,5000,10000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "\n",
    "#gsExtC = GridSearchCV(ExtraTreesClassifier, param_grid = ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "\n",
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(GradientBoostingClassifier(),param_grid = gb_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "precision_score_list = []\n",
    "precision_train_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    print(model_str,':',models.best_params_)\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))  \n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "precision_score_result[stock_code]=precision_score_list\n",
    "precision_train_result[stock_code]=precision_train_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'021240': [{'GridSearchCV': 0.6619718309859155},\n",
       "          {'GridSearchCV': 0.6901408450704225},\n",
       "          {'GridSearchCV': 0.5352112676056338},\n",
       "          {'GridSearchCV': 0.676056338028169},\n",
       "          {'LinearDiscriminantAnalysis': 0.6338028169014085}]})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(GradientBoostingClassifier(),param_grid = gb_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[\n",
    "'RandomForestClassifier',\n",
    "'ExtraTreesClassifier',\n",
    "'GradientBoostingClassifier',\n",
    "'KNeighborsClassifier'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'021240': [{'RandomForestClassifier': 0.6619718309859155}, {'ExtraTreesClassifier': 0.6901408450704225}, {'GradientBoostingClassifier': 0.5352112676056338}, {'KNeighborsClassifier': 0.676056338028169}, {'LinearDiscriminantAnalysis': 0.6338028169014085}]})\n",
      "Counter({'021240': [{'RandomForestClassifier': 0.6923076923076923}, {'ExtraTreesClassifier': 0.6853146853146853}, {'GradientBoostingClassifier': 0.5384615384615384}, {'KNeighborsClassifier': 0.6293706293706294}, {'LinearDiscriminantAnalysis': 0.5524475524475524}]})\n",
      "Counter({'021240': [{'RandomForestClassifier': 0.6619718309859155}, {'ExtraTreesClassifier': 0.6901408450704225}, {'GradientBoostingClassifier': 0.5352112676056338}, {'KNeighborsClassifier': 0.676056338028169}, {'LinearDiscriminantAnalysis': 0.6338028169014085}]})\n",
      "Counter({'021240': [{'RandomForestClassifier': 0.6842105263157895}, {'ExtraTreesClassifier': 0.7}, {'GradientBoostingClassifier': 0.5352112676056338}, {'KNeighborsClassifier': 0.7777777777777778}, {'LinearDiscriminantAnalysis': 0.6071428571428571}]})\n"
     ]
    }
   ],
   "source": [
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = model_result[stock_code][idx]['GridSearchCV']\n",
    "    model_result[stock_code][idx] = tmp_dict\n",
    "print(model_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = train_result[stock_code][idx]['GridSearchCV']\n",
    "    train_result[stock_code][idx] = tmp_dict\n",
    "print(train_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = test_result[stock_code][idx]['GridSearchCV']\n",
    "    test_result[stock_code][idx] = tmp_dict\n",
    "print(test_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = precision_score_result[stock_code][idx]['GridSearchCV']\n",
    "    precision_score_result[stock_code][idx] = tmp_dict\n",
    "print(precision_score_result)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RandomForestClassifier': 0.6923076923076923},\n",
       " {'ExtraTreesClassifier': 0.6853146853146853},\n",
       " {'GradientBoostingClassifier': 0.5384615384615384},\n",
       " {'KNeighborsClassifier': 0.6293706293706294},\n",
       " {'LinearDiscriminantAnalysis': 0.5524475524475524}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RandomForestClassifier': 0.6619718309859155},\n",
       " {'ExtraTreesClassifier': 0.6901408450704225},\n",
       " {'GradientBoostingClassifier': 0.5352112676056338},\n",
       " {'KNeighborsClassifier': 0.676056338028169},\n",
       " {'LinearDiscriminantAnalysis': 0.6338028169014085}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'021240': [{'RandomForestClassifier': 0.6842105263157895},\n",
       "          {'ExtraTreesClassifier': 0.7},\n",
       "          {'GradientBoostingClassifier': 0.5352112676056338},\n",
       "          {'KNeighborsClassifier': 0.7777777777777778},\n",
       "          {'LinearDiscriminantAnalysis': 0.6071428571428571}]})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC': (0.86, 0.3712, 0.33999999999999997),\n",
       " 'RF': (0.86, 0.6112, 0.33999999999999997),\n",
       " 'ET': (0.86, 0.8512000000000001, 0.33999999999999997),\n",
       " 'GB': (0.6287999999999998, 0.86, 0.33999999999999997),\n",
       " 'KNN': (0.38880000000000003, 0.86, 0.33999999999999997),\n",
       " 'LR': (0.33999999999999997, 0.86, 0.5312000000000001),\n",
       " 'XGB': (0.33999999999999997, 0.86, 0.7712000000000001),\n",
       " 'LSVC': (0.33999999999999997, 0.7087999999999995, 0.86),\n",
       " 'MLP': (0.33999999999999997, 0.4687999999999997, 0.86),\n",
       " 'LDA': (0.4511999999999997, 0.33999999999999997, 0.86),\n",
       " 'GNB': (0.6912000000000003, 0.33999999999999997, 0.86),\n",
       " 'MNB': (0.86, 0.33999999999999997, 0.7887999999999993),\n",
       " 'BNB': (0.86, 0.33999999999999997, 0.5487999999999995)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SVC': 0.5384615384615384,\n",
       "         'RF': 0.9370629370629371,\n",
       "         'ET': 0.965034965034965,\n",
       "         'GB': 0.8881118881118881,\n",
       "         'KNN': 0.6783216783216783,\n",
       "         'LR': 0.5384615384615384,\n",
       "         'XGB': 0.7482517482517482,\n",
       "         'LSVC': 0.5314685314685315,\n",
       "         'MLP': 0.5384615384615384,\n",
       "         'LDA': 0.5524475524475524,\n",
       "         'GNB': 0.5454545454545454,\n",
       "         'MNB': 0.5384615384615384,\n",
       "         'BNB': 0.5384615384615384})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in train_accuracy_list:\n",
    "    for key in element.keys():\n",
    "        if key.find('RandomForestClassifier')>=0:\n",
    "            element['RF'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('ExtraTreesClassifier')>=0:        \n",
    "            element['ET'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GradientBoostingClassifier')>=0:        \n",
    "            element['GB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('KNeighborsClassifier')>=0:        \n",
    "            element['KNN'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LogisticRegression')>=0:        \n",
    "            element['LR'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('XGBClassifier')>=0:        \n",
    "            element['XGB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearSVC')>=0:        \n",
    "            element['LSVC'] = element[key]\n",
    "            del element[key]        \n",
    "        if key.find('MLPClassifier')>=0:        \n",
    "            element['MLP'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearDiscriminantAnalysis')>=0:        \n",
    "            element['LDA'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GaussianNB')>=0:        \n",
    "            element['GNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('MultinomialNB')>=0:        \n",
    "            element['MNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('BernoulliNB')>=0:        \n",
    "            element['BNB'] = element[key]\n",
    "            del element[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC': (0.86, 0.3712, 0.33999999999999997),\n",
       " 'RF': (0.86, 0.6112, 0.33999999999999997),\n",
       " 'ET': (0.86, 0.8512000000000001, 0.33999999999999997),\n",
       " 'GB': (0.6287999999999998, 0.86, 0.33999999999999997),\n",
       " 'KNN': (0.38880000000000003, 0.86, 0.33999999999999997),\n",
       " 'LR': (0.33999999999999997, 0.86, 0.5312000000000001),\n",
       " 'XGB': (0.33999999999999997, 0.86, 0.7712000000000001),\n",
       " 'LSVC': (0.33999999999999997, 0.7087999999999995, 0.86),\n",
       " 'MLP': (0.33999999999999997, 0.4687999999999997, 0.86),\n",
       " 'LDA': (0.4511999999999997, 0.33999999999999997, 0.86),\n",
       " 'GNB': (0.6912000000000003, 0.33999999999999997, 0.86),\n",
       " 'MNB': (0.86, 0.33999999999999997, 0.7887999999999993),\n",
       " 'BNB': (0.86, 0.33999999999999997, 0.5487999999999995)}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RF': 0.6923076923076923},\n",
       " {'ET': 0.6853146853146853},\n",
       " {'GB': 0.5384615384615384},\n",
       " {'KNN': 0.6293706293706294},\n",
       " {'LDA': 0.5524475524475524}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict=Counter()\n",
    "for element in train_accuracy_list:\n",
    "    train_dict.update(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'RF': 0.6923076923076923,\n",
       "         'ET': 0.6853146853146853,\n",
       "         'GB': 0.5384615384615384,\n",
       "         'KNN': 0.6293706293706294,\n",
       "         'LDA': 0.5524475524475524})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_color_dict={}\n",
    "for key in train_dict.keys():\n",
    "    tmp_color_dict[key] = color_dict[key]\n",
    "color_dict = tmp_color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x253a10e1940>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_keys=sorted(train_dict,key=lambda x:train_dict[x],reverse=True)\n",
    "train_values=sorted(train_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Train)',fontsize = 20)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.ylim((0.5,0.7))\n",
    "\n",
    "sns.barplot(train_keys,train_values,palette=[color_dict[key] for key in train_keys]) # 그래프가 바뀌어도 분류기에 대한 색깔이 변치 않기위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ExtraTreesClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-52228bc3051b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Extratrees'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Extratrees'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Kneighbors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Kneighbors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolor_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-108-52228bc3051b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Extratrees'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Extratrees'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Kneighbors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Kneighbors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolor_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'ExtraTreesClassifier'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dict=Counter()\n",
    "for element in test_accuracy_list:\n",
    "    test_dict.update(element)\n",
    "test_keys=sorted(test_dict.keys(),key=lambda x:test_dict[x],reverse=True)\n",
    "test_values=sorted(test_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim((0.5,0.75))\n",
    "plt.text(0,test_dict['Extratrees'],round(test_dict['Extratrees'],3),fontsize=20)\n",
    "plt.text(1,test_dict['Kneighbors'],round(test_dict['Kneighbors'],3),fontsize=20)\n",
    "sns.barplot(test_keys,test_values,palette=[color_dict[key] for key in test_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in precision_score_list:\n",
    "    for key in element.keys():\n",
    "        if key.find('RandomForestClassifier')>=0:\n",
    "            element['RF'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('ExtraTreesClassifier')>=0:        \n",
    "            element['ET'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GradientBoostingClassifier')>=0:        \n",
    "            element['GB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('KNeighborsClassifier')>=0:        \n",
    "            element['KNN'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LogisticRegression')>=0:        \n",
    "            element['LR'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('XGBClassifier')>=0:        \n",
    "            element['XGB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearSVC')>=0:        \n",
    "            element['LSVC'] = element[key]\n",
    "            del element[key]        \n",
    "        if key.find('MLPClassifier')>=0:        \n",
    "            element['MLP'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('LinearDiscriminantAnalysis')>=0:        \n",
    "            element['LDA'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('GaussianNB')>=0:        \n",
    "            element['GNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('MultinomialNB')>=0:        \n",
    "            element['MNB'] = element[key]\n",
    "            del element[key]\n",
    "        if key.find('BernoulliNB')>=0:        \n",
    "            element['BNB'] = element[key]\n",
    "            del element[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict={}\n",
    "for element in precision_score_list:\n",
    "    precision_score_dict.update(element)\n",
    "precision_score_keys=sorted(precision_score_dict.keys(),key=lambda x:precision_score_dict[x],reverse=True)\n",
    "precision_score_values=sorted(precision_score_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Precision(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim((0,0.8))\n",
    "plt.text(1,precision_score_dict['Extratrees'],round(precision_score_dict['Extratrees'],3),fontsize=20)\n",
    "plt.text(0,precision_score_dict['Kneighbors'],round(precision_score_dict['Kneighbors'],3),fontsize=20)\n",
    "sns.barplot(precision_score_keys,precision_score_values,palette=[color_dict[key] for key in precision_score_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_tt1 = train_dict-test_dict\n",
    "half_tt2 = test_dict - train_dict\n",
    "half_tt1.update(half_tt2)\n",
    "train_test_dict = half_tt1\n",
    "test_keys=sorted(train_test_dict.keys(),key=lambda x:train_test_dict[x],reverse=True)\n",
    "test_values=sorted(train_test_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Difference(Train,Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.text(1,train_test_dict['Kneighbors'],train_test_dict['Kneighbors'])\n",
    "plt.text(3,train_test_dict['Extratrees'],train_test_dict['Extratrees'])\n",
    "sns.barplot(test_keys,test_values,palette=[color_dict[key] for key in test_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상위모델 선정 x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "precision_score_result=Counter()\n",
    "precision_train_result = Counter()\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "\n",
    "svc_param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state }\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [3, 5, 10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"bootstrap\": [False,True],\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\",'exponential'],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': [200,400,600],\n",
    "              'max_features': [0.3, 0.1], 'random_state':random_state  \n",
    "              }\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [3,4,5,10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': Cs                                   \n",
    "              }\n",
    "\n",
    "lda_param_grid = {'solver' : [\"svd\",'lsqr','eigen'],\n",
    "              'shrinkage ' : ['auto'], 'random_state':random_state \n",
    "              }\n",
    "\n",
    "kneighbor_param_grid = {'n_neighbors':list(range(1,31))}\n",
    "\n",
    "xgboost_param_grid ={\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "     'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "     'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'n_estimators':[100,500,1000,2000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'priors':None, 'random_state':random_state \n",
    "}\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,0.1,1,10,100],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[1000,2000,5000,10000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "\n",
    "#gsExtC = GridSearchCV(ExtraTreesClassifier, param_grid = ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "classifiers.append(GridSearchCV(SVC(), svc_param_grid, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(GradientBoostingClassifier(),param_grid = gb_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LogisticRegression(penalty='l2'),param_grid = logistic_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(XGBClassifier(silent=True, learning_rate=0.01, objective='binary:logistic'),param_grid=xgboost_param_grid,cv=nfolds,scoring=scoring,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LinearSVC(),param_grid=linearscv_param_grid, scoring=scoring, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(MLPClassifier(),param_grid=mlp_param_grid,cv=nfolds,n_jobs=-1)) # 제외\n",
    "\n",
    "\n",
    "\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())# 튜닝 불가능\n",
    "classifiers_not.append(GaussianNB())\n",
    "classifiers_not.append(MultinomialNB())\n",
    "classifiers_not.append(BernoulliNB())\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "precision_score_list = []\n",
    "precision_train_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    print(model_str,':',models.best_params_)\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    \n",
    "    \n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "precision_score_result[stock_code]=precision_score_list\n",
    "precision_train_result[stock_code]=precision_train_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = model_result[stock_code][idx]['GridSearchCV']\n",
    "    model_result[stock_code][idx] = tmp_dict\n",
    "print(model_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = train_result[stock_code][idx]['GridSearchCV']\n",
    "    train_result[stock_code][idx] = tmp_dict\n",
    "print(train_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = test_result[stock_code][idx]['GridSearchCV']\n",
    "    test_result[stock_code][idx] = tmp_dict\n",
    "print(test_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = precision_score_result[stock_code][idx]['GridSearchCV']\n",
    "    precision_score_result[stock_code][idx] = tmp_dict\n",
    "print(precision_score_result)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict= dict(zip(train_dict.keys(),sns.color_palette(\"hls\", len(classifiers)+len(classifiers_not))))\n",
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list #tmp_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.color_palette()\n",
    "sns.palplot(sns.color_palette(\"hls\", len(classifiers)+len(classifiers_not)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in sns.color_palette(\"hls\", len(classifiers)+len(classifiers_not)):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict={}\n",
    "for element in train_accuracy_list:\n",
    "    train_dict.update(element)\n",
    "train_keys=sorted(train_dict,key=lambda x:train_dict[x],reverse=True)\n",
    "train_values=sorted(train_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Train)',fontsize = 20)\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(train_keys,train_values,palette=[color_dict[key] for key in train_keys]) # 그래프가 바뀌어도 분류기에 대한 색깔이 변치 않기위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_train_dict={}\n",
    "for element in precision_train_list:\n",
    "    precision_train_dict.update(element)\n",
    "precision_train_keys=sorted(precision_train_dict.keys(),key=lambda x:precision_train_dict[x],reverse=True)\n",
    "precision_train_values=sorted(precision_train_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(precision_train)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(precision_train_keys,precision_train_values,palette=[color_dict[key] for key in precision_train_keys])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict={}\n",
    "for element in test_accuracy_list:\n",
    "    test_dict.update(element)\n",
    "test_keys=sorted(test_dict.keys(),key=lambda x:test_dict[x],reverse=True)\n",
    "test_values=sorted(test_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Accuracy(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(test_keys,test_values,palette=[color_dict[key] for key in test_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix_dict={}\n",
    "# for element in confusion_matrix_list:\n",
    "#     confusion_matrix_dict.update(element)\n",
    "# confusion_matrix_keys=sorted(confusion_matrix_dict,key=operator.itemgetter(1),reverse=True)\n",
    "# confusion_matrix_values=sorted(confusion_matrix_dict.values(),reverse=True)\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.xticks(rotation=45)\n",
    "# sns.barplot(confusion_matrix_keys,confusion_matrix_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict={}\n",
    "for element in precision_score_list:\n",
    "    precision_score_dict.update(element)\n",
    "precision_score_keys=sorted(precision_score_dict.keys(),key=lambda x:precision_score_dict[x],reverse=True)\n",
    "precision_score_values=sorted(precision_score_dict.values(),reverse=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Precision(Test)',fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(precision_score_keys,precision_score_values,palette=[color_dict[key] for key in precision_score_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_list #tmp_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list #tmp_dict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_list #tmp_dict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling 이전 end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_pos_neg_processing(X_train_raw)\n",
    "X_test = train_pos_neg_processing(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling 이후 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['긍정'] = X_train['긍정']/X_train['긍정'].max()\n",
    "X_train['부정'] = X_train['부정']/X_train['부정'].max()\n",
    "X_test['긍정'] = X_test['긍정']/X_test['긍정'].max()\n",
    "X_test['부정'] = X_test['부정']/X_test['부정'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "\n",
    "svc_param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state }\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [3, 5, 10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"bootstrap\": [False,True],\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\",'exponential'],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': [200,400,600],\n",
    "              'max_features': [0.3, 0.1], 'random_state':random_state  \n",
    "              }\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [3,4,5,10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': Cs                                   \n",
    "              }\n",
    "\n",
    "lda_param_grid = {'solver' : [\"svd\",'lsqr','eigen'],\n",
    "              'shrinkage ' : ['auto'], 'random_state':random_state \n",
    "              }\n",
    "\n",
    "kneighbor_param_grid = {'n_neighbors':list(range(1,31))}\n",
    "\n",
    "xgboost_param_grid ={\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "     'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "     'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'n_estimators':[100,500,1000,2000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'priors':None, 'random_state':random_state \n",
    "}\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,0.1,1,10,100],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[1000,2000,5000,10000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "\n",
    "#gsExtC = GridSearchCV(ExtraTreesClassifier, param_grid = ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "classifiers.append(GridSearchCV(SVC(), svc_param_grid, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(GradientBoostingClassifier(),param_grid = gb_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LogisticRegression(penalty='l2'),param_grid = logistic_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(XGBClassifier(silent=True, learning_rate=0.01, objective='binary:logistic'),param_grid=xgboost_param_grid,cv=nfolds,scoring=scoring,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LinearSVC(),param_grid=linearscv_param_grid, scoring=scoring, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(MLPClassifier(),param_grid=mlp_param_grid,cv=nfolds,n_jobs=-1)) # 제외\n",
    "\n",
    "\n",
    "\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())# 튜닝 불가능\n",
    "classifiers_not.append(GaussianNB())\n",
    "classifiers_not.append(MultinomialNB())\n",
    "classifiers_not.append(BernoulliNB())\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    print(model_str,':',models.best_params_)\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pre)\n",
    "    tmp_dict5 = {}\n",
    "    tmp_dict5[model_str] = metrics.auc(fpr, tpr)\n",
    "    auc_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pre)\n",
    "    tmp_dict5 = {}\n",
    "    tmp_dict5[model_str] = metrics.auc(fpr, tpr)\n",
    "    auc_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "auc_result[stock_code] = auc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=['svc',\n",
    "'randomforestclassifier',\n",
    "'extratreesclassifier',\n",
    "'gradientboostingclassifier',\n",
    "'kneighborsclassfier',\n",
    "'logisticregression',\n",
    "'xgbclassifier',\n",
    "'linearsvc',\n",
    "'mlpclassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = confusion_matrix_result[stock_code][idx]['GridSearchCV']\n",
    "    confusion_matrix_result[stock_code][idx] = tmp_dict\n",
    "print(confusion_matrix_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = model_result[stock_code][idx]['GridSearchCV']\n",
    "    model_result[stock_code][idx] = tmp_dict\n",
    "print(model_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = train_result[stock_code][idx]['GridSearchCV']\n",
    "    train_result[stock_code][idx] = tmp_dict\n",
    "print(train_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = test_result[stock_code][idx]['GridSearchCV']\n",
    "    test_result[stock_code][idx] = tmp_dict\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling 이후 end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost의 장점\n",
    "1. 규제가 가능하다.  \n",
    "2. 병렬처리 가능 - 트리 구조를 생각하면 된다.  \n",
    "3. Built-in Cross-Validation\n",
    "4. max_depths 까지 간 후에 backword로 Tree Pruning:\n",
    "5. Continue on Existing Model\n",
    "6. XGBoost allow users to define custom optimization objectives and evaluation criteria.  \n",
    "\n",
    "- 참고 사이트  \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "max_features = [1]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "\n",
    "svc_param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state }\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [3, 5, 10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"bootstrap\": [False,True],\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\",'exponential'],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': [200,400,600],\n",
    "              'max_features': [0.3, 0.1], 'random_state':random_state  \n",
    "              }\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [3,4,5,10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': Cs                                   \n",
    "              }\n",
    "\n",
    "lda_param_grid = {'solver' : [\"svd\",'lsqr','eigen'],\n",
    "              'shrinkage ' : ['auto'], 'random_state':random_state \n",
    "              }\n",
    "\n",
    "kneighbor_param_grid = {'n_neighbors':list(range(1,31))}\n",
    "\n",
    "xgboost_param_grid ={\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "     'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "     'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'n_estimators':[100,500,1000,2000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'priors':None, 'random_state':random_state \n",
    "}\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,0.1,1,10,100],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[1000,2000,5000,10000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "\n",
    "#gsExtC = GridSearchCV(ExtraTreesClassifier, param_grid = ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "classifiers.append(GridSearchCV(SVC(), svc_param_grid, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(GradientBoostingClassifier(),param_grid = gb_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LogisticRegression(penalty='l2'),param_grid = logistic_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(XGBClassifier(silent=True, learning_rate=0.01, objective='binary:logistic'),param_grid=xgboost_param_grid,cv=nfolds,scoring=scoring,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LinearSVC(),param_grid=linearscv_param_grid, scoring=scoring, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(MLPClassifier(),param_grid=mlp_param_grid,cv=nfolds,n_jobs=-1)) # 제외\n",
    "\n",
    "\n",
    "\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())# 튜닝 불가능\n",
    "classifiers_not.append(GaussianNB())\n",
    "classifiers_not.append(MultinomialNB())\n",
    "classifiers_not.append(BernoulliNB())\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    print(model_str,':',models.best_params_)\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pre)\n",
    "    tmp_dict5 = {}\n",
    "    tmp_dict5[model_str] = metrics.auc(fpr, tpr)\n",
    "    auc_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pre)\n",
    "    tmp_dict5 = {}\n",
    "    tmp_dict5[model_str] = metrics.auc(fpr, tpr)\n",
    "    auc_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "auc_result[stock_code] = auc_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV : {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}\n",
    "GridSearchCV : {'criterion': 'gini', 'max_depth': 5, 'max_features': 12, 'n_estimators': 500}\n",
    "GridSearchCV : {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 15, 'max_features': 11, 'n_estimators': 500}\n",
    "GridSearchCV : {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'max_features': 0.3, 'min_samples_leaf': 200, 'n_estimators': 500}\n",
    "GridSearchCV : {'n_neighbors': 19}\n",
    "GridSearchCV : {'C': 0.01}\n",
    "GridSearchCV : {'colsample_bytree': 0.8, 'gamma': 0.4, 'n_estimators': 1000, 'reg_alpha': 1e-05, 'subsample': 0.75}\n",
    "GridSearchCV : {'C': 0.001, 'penalty': 'l2'}\n",
    "GridSearchCV : {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result = Counter()\n",
    "# train_result= Counter()\n",
    "# test_result = Counter()\n",
    "# confusion_matrix_result = Counter()\n",
    "# auc_result = Counter()\n",
    "# one_code_list = all_dict[stock_code]\n",
    "# tag_list = [tag[0] for tag in one_code_list[:int(len(one_code_list)*0.2)]]\n",
    "# y = np.where(earning_data>=0,1,0)\n",
    "# x= data_filter_freq[tag_list]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, shuffle=False)\n",
    "# lenx=X_train.shape\n",
    "# # if lenx[0]<=10 or lenx[1]<=2 :\n",
    "# #     continue\n",
    "# random_state = 2\n",
    "# classifiers = []\n",
    "# # rf_param_grid = {\"max_depth\": [10,15,20],\n",
    "# #               \"max_features\": [7,8,9,10,11,12],\n",
    "# #               \"n_estimators\" :[2000],\n",
    "# #               \"criterion\": [\"gini\",'entropy']}\n",
    "\n",
    "\n",
    "# # gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "# classifiers.append(SVC(random_state=random_state,C=0.0001))\n",
    "# classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "# classifiers.append(RandomForestClassifier(random_state=random_state,n_estimators=1000,max_depth=3))\n",
    "# classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "# classifiers.append(GradientBoostingClassifier(random_state=random_state,learning_rate=0.01))\n",
    "# classifiers.append(MLPClassifier(random_state=random_state,max_iter=2000)) # 제외\n",
    "# classifiers.append(KNeighborsClassifier())\n",
    "# classifiers.append(LogisticRegression(random_state = random_state,C=0.001))\n",
    "# classifiers.append(LinearDiscriminantAnalysis())# 여기까지\n",
    "# classifiers.append(GaussianNB())\n",
    "# classifiers.append(MultinomialNB())\n",
    "# classifiers.append(BernoulliNB())\n",
    "# classifiers.append(XGBClassifier(silent=True, learning_rate=0.01, subsample=0.8, objective='binary:logistic',n_estimators=1000,reg_alpha=0.3))\n",
    "# classifiers.append(LinearSVC(random_state=100,C=0.01))\n",
    "# #classifiers.append(XGBClassifier())\n",
    "# test_accuracy_list = []\n",
    "# train_accuracy_list= [] \n",
    "# model_accuracy_list= []\n",
    "# confusion_matrix_list = []\n",
    "# auc_list = []\n",
    "# for models in classifiers:\n",
    "#     #print(models)\n",
    "#     models.fit(X_train,y_train)\n",
    "#     model_str = str(models).split('(')[0]\n",
    "#     pre = models.predict(X_test)\n",
    "    \n",
    "#     tmp_dict1 = {}\n",
    "#     tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "#     test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "#     tmp_dict2 = {}\n",
    "#     tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "#     train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "#     tmp_dict3 = {}\n",
    "#     tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "#     model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "#     # 전역변수로, 지역변수 문제라 생각한다.\n",
    "#     tmp_dict4 = {}\n",
    "#     tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "#     confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y_test, pre)\n",
    "#     tmp_dict5 = {}\n",
    "#     tmp_dict5[model_str] = metrics.auc(fpr, tpr)\n",
    "#     auc_list.append(tmp_dict5)\n",
    "#     #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "    \n",
    "# train_result[stock_code] = train_accuracy_list\n",
    "# test_result[stock_code] = test_accuracy_list\n",
    "# model_result[stock_code] = model_accuracy_list\n",
    "# confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "# auc_result[stock_code] = auc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in classifiers:\n",
    "#     print(model)\n",
    "#     #model_str = str(model)\n",
    "#     #print(type(model_str))\n",
    "#     #print(model_str.split('(')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_y = y.sum()/len(y)\n",
    "print(ratio_y,1-ratio_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_y_test = y_test.sum()/len(y_test)\n",
    "print(ratio_y_test,1-ratio_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = LinearDiscriminantAnalysis(solver='eigen')\n",
    "# models.fit(X_train,y_train)\n",
    "# model_str = str(models).split('(')[0]\n",
    "# pre = models.predict(X_test)\n",
    "# models.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "# models.fit(X_train,y_train)\n",
    "# model_str = str(models).split('(')[0]\n",
    "# pre = models.predict(X_test)\n",
    "# models.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=['svc',\n",
    "'randomforestclassifier',\n",
    "'extratreesclassifier',\n",
    "'gradientboostingclassifier',\n",
    "'kneighborsclassfier',\n",
    "'logisticregression',\n",
    "'xgbclassifier',\n",
    "'linearsvc',\n",
    "'mlpclassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = confusion_matrix_result[stock_code][idx]['GridSearchCV']\n",
    "    confusion_matrix_result[stock_code][idx] = tmp_dict\n",
    "print(confusion_matrix_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = model_result[stock_code][idx]['GridSearchCV']\n",
    "    model_result[stock_code][idx] = tmp_dict\n",
    "print(model_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = train_result[stock_code][idx]['GridSearchCV']\n",
    "    train_result[stock_code][idx] = tmp_dict\n",
    "print(train_result)\n",
    "for idx,element in enumerate(model_list):    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[element] = test_result[stock_code][idx]['GridSearchCV']\n",
    "    test_result[stock_code][idx] = tmp_dict\n",
    "print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix_result)\n",
    "print(model_result)\n",
    "print(train_result)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(earning_data)-2):\n",
    "#     eidx = earning_data.index\n",
    "#     # 수익률 이전 행 날짜가 전날 날짜가 아니라 그이상 차이가 날때\n",
    "#     if (eidx[i+1] - eidx[i]).days > 1:\n",
    "#         # 휴일 or 주말이 끼면 그 날을 포함해서 다음 날에 반영한다.\n",
    "#         try:\n",
    "#             #data_filter_freq가 earning_data 보다 날짜가 하나 적다.\n",
    "#             print(data_filter_freq[eidx[i]+relativedelta(days=1):eidx[i+1]].sum()) # [i]는 [i+1]보다 1이상 차이난다.\n",
    "#             # 근데 data_filter_freq 데이터에서 earning_data의 인덱스가 없는 경우가 있다.\n",
    "#             data_filter_freq.loc[eidx[i+1],:] = data_filter_freq[eidx[i]+relativedelta(days=1):eidx[i+1]].sum()\n",
    "#             #del(data_filter_freq[eidx[i]+relativedelta(days=1):eidx[i+1]-relativedelta(days=1)])\n",
    "\n",
    "#             #data_filter_freq.drop(pd.date_range(eidx[i]+relativedelta(days=1),eidx[i+1]-relativedelta(days=1)),axis=0,inplace=True)\n",
    "#         except:\n",
    "#             print(i)\n",
    "#         #KeyError 발생\n",
    "#         #해결방법\n",
    "#         #1.존재 여부를 일일이 살펴 제어문을 걸어준다.\n",
    "#         #2. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'max_features': 8, 'n_estimators': 500, 'random_state': 4000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "모든 학습 모델들이 overfitting하여 이에 대한 해결책이 필요하다.\n",
    "1. 학습 데이터 비율증가.\n",
    "2. 파라미터 튜닝  - 가장 성능이 좋은 extraclassifier에 대해서 해준다.\n",
    "\n",
    "\n",
    "- n_estimators  값 증가\n",
    "- max_feature 줄이기\n",
    "- max_depths 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier(silent=True, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter({'021240': [{'svc': 0.647887323943662}, {'randomforestclassifier': 0.676056338028169}, {'extratreesclassifier': 0.5774647887323944}, {'gradientboostingclassifier': 0.5352112676056338}, {'kneighborsclassfier': 0.6619718309859155}, {'logisticregression': 0.5352112676056338}, {'xgbclassifier': 0.6619718309859155}, {'linearsvc': 0.5352112676056338}, {'mlpclassifier': 0.676056338028169}, {'LinearDiscriminantAnalysis': 0.6901408450704225}, {'GaussianNB': 0.5492957746478874}, {'MultinomialNB': 0.5352112676056338}, {'BernoulliNB': 0.5492957746478874}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_pos = ()\n",
    "for k,i in enumerate(train_accuracy_list):\n",
    "    for s in i.values():\n",
    "        k_pos = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = ('svc', 'randomforestclassifier', 'extratreesclassifier', 'gradientboostingclassifier', 'kneighborsclassfier','logisticregression'\n",
    "         ,'xgbclassifier','linearsvc','mlpclassifier','LinearDiscriminantAnalysis','GaussianNB','MultinomialNB','BernoulliNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.bar(y_pos, performance, align='center',\n",
    "        color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(people)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_title('How fast do you want to go today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = Counter()\n",
    "train_result= Counter()\n",
    "test_result = Counter()\n",
    "confusion_matrix_result = Counter()\n",
    "auc_result = Counter()\n",
    "precision_score_result=Counter()\n",
    "precision_train_result = Counter()\n",
    "lenx=X_train.shape\n",
    "# if lenx[0]<=10 or lenx[1]<=2:\n",
    "#     continue\n",
    "classifiers = []\n",
    "classifiers_not = []\n",
    "random_state = [4000]\n",
    "\n",
    "\n",
    "\n",
    "# gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernel = ['linear', 'rbf', 'sigmoid']#'precomputed','poly'\n",
    "nfolds=5\n",
    "criterion = [\"gini\", 'entropy']\n",
    "#grid_search = GridSearchCV(SVC(), param_grid_svc, cv=nfolds)\n",
    "n_estimators = [500,1000,2000]\n",
    "learning_rate = [0.01]\n",
    "max_depth = [3, 5, 10, 15 ,20]\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "scoring = 'accuracy'\n",
    "n_jobs= -1\n",
    "penalty= ['l2']\n",
    "max_features = [2]\n",
    "linearscv_param_grid = {'C':Cs, 'penalty':penalty, 'random_state':random_state }\n",
    "\n",
    "svc_param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel, 'random_state':random_state }\n",
    "\n",
    "ex_param_grid = {\"max_depth\": [3, 5, 10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"bootstrap\": [False,True],\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "\n",
    "gb_param_grid = {'loss' : [\"deviance\",'exponential'],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': [200,400,600],\n",
    "              'max_features': [0.3, 0.1], 'random_state':random_state  \n",
    "              }\n",
    "\n",
    "rf_param_grid = {\"max_depth\": [3,4,5,10,15,20],\n",
    "              \"max_features\": max_features,\n",
    "              \"n_estimators\" :n_estimators,\n",
    "              \"criterion\": criterion, 'random_state':random_state }\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'C': Cs                                   \n",
    "              }\n",
    "\n",
    "lda_param_grid = {'solver' : [\"svd\",'lsqr','eigen'],\n",
    "              'shrinkage ' : ['auto'], 'random_state':random_state \n",
    "              }\n",
    "\n",
    "kneighbor_param_grid = {'n_neighbors':list(range(1,31))}\n",
    "\n",
    "xgboost_param_grid ={\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "     'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "     'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'n_estimators':[100,500,1000,2000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "naive_bayes_param_grid = {\n",
    "    'priors':None, 'random_state':random_state \n",
    "}\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,0.1,1,10,100],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[1000,2000,5000,10000], 'random_state':random_state \n",
    "}\n",
    "\n",
    "\n",
    "#gsExtC = GridSearchCV(ExtraTreesClassifier, param_grid = ex_param_grid, cv=nfold, scoring=\"auc\")\n",
    "\n",
    "print('X_train_shape:',X_train.shape)\n",
    "classifiers.append(GridSearchCV(SVC(), svc_param_grid, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(RandomForestClassifier(),param_grid = rf_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(ExtraTreesClassifier(), param_grid = ex_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(KNeighborsClassifier(),param_grid=kneighbor_param_grid,cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LogisticRegression(penalty='l2'),param_grid = logistic_param_grid, cv=nfolds, scoring=scoring, n_jobs=-1))\n",
    "\n",
    "classifiers.append(GridSearchCV(XGBClassifier(silent=True, learning_rate=0.01, objective='binary:logistic'),param_grid=xgboost_param_grid,cv=nfolds,scoring=scoring,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(LinearSVC(),param_grid=linearscv_param_grid, scoring=scoring, cv=nfolds,n_jobs=-1))\n",
    "classifiers.append(GridSearchCV(MLPClassifier(),param_grid=mlp_param_grid,cv=nfolds,n_jobs=-1)) # 제외\n",
    "\n",
    "\n",
    "\n",
    "classifiers_not.append(LinearDiscriminantAnalysis())# 튜닝 불가능\n",
    "classifiers_not.append(GaussianNB())\n",
    "classifiers_not.append(MultinomialNB())\n",
    "classifiers_not.append(BernoulliNB())\n",
    "\n",
    "\n",
    "\n",
    "#classifiers.append(XGBClassifier())\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list= [] \n",
    "model_accuracy_list= []\n",
    "confusion_matrix_list = []\n",
    "precision_score_list = []\n",
    "precision_train_list = []\n",
    "auc_list = []\n",
    "for models in classifiers:\n",
    "    #print(models)\n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    print(model_str,':',models.best_params_)\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))\n",
    "for models in classifiers_not:\n",
    "    \n",
    "    models.fit(X_train,y_train)\n",
    "    \n",
    "    model_str = str(models).split('(')[0]\n",
    "    pre = models.predict(X_test)\n",
    "    \n",
    "    tmp_dict1 = {}\n",
    "    tmp_dict1[model_str] = models.score(X_test,y_test)\n",
    "    test_accuracy_list.append(tmp_dict1)\n",
    "    \n",
    "    tmp_dict2 = {}\n",
    "    tmp_dict2[model_str] = models.score(X_train,y_train)\n",
    "    train_accuracy_list.append(tmp_dict2)\n",
    "    \n",
    "    tmp_dict3 = {}\n",
    "    tmp_dict3[model_str] = metrics.accuracy_score(y_test, pre)\n",
    "    model_accuracy_list.append(tmp_dict3)\n",
    "    \n",
    "    # 전역변수로, 지역변수 문제라 생각한다.\n",
    "    tmp_dict4 = {}\n",
    "    tmp_dict4[model_str] = confusion_matrix(y_test,pre)\n",
    "    confusion_matrix_list.append(tmp_dict4)\n",
    "    \n",
    "    tmp_dict5 ={}\n",
    "    tmp_dict5[model_str] = metrics.precision_score(y_test,pre)\n",
    "    precision_score_list.append(tmp_dict5)\n",
    "    \n",
    "    \n",
    "    #confusion_matrix_list.append(confusion_matrix(y_test,pre))    \n",
    "\n",
    "    \n",
    "train_result[stock_code] = train_accuracy_list\n",
    "test_result[stock_code] = test_accuracy_list\n",
    "model_result[stock_code] = model_accuracy_list\n",
    "confusion_matrix_result[stock_code] = confusion_matrix_list\n",
    "precision_score_result[stock_code]=precision_score_list\n",
    "precision_train_result[stock_code]=precision_train_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_code = '000660'\n",
    "path = './data/freq2/naver_{0}_freq.parquet/'.format(stock_code)\n",
    "abs_path = os.path.abspath('../file_list/crawl_data/naver_{0}.csv'.format(stock_code))\n",
    "csv_file = pd.read_csv(abs_path,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, element in enumerate(csv_file.loc[:,7]):\n",
    "    if str(element).find('의견')>=0:\n",
    "        print(idx)\n",
    "        print(csv_file.loc[idx,1])\n",
    "        print(element)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.loc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
